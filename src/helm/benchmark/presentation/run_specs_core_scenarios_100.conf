# Main `RunSpec`s for the benchmarking the core scenarios.

entries: [

  ## Reading comprehension

  {description: "boolq:model=text,max_eval_instances=100", priority: 1}
  {description: "narrative_qa:model=text,max_eval_instances=100", priority: 2}
  {description: "quac:model=text,max_eval_instances=100", priority: 1}

  ## Reading comprehension and closedbook QA variants

  {description: "natural_qa:model=text,mode=openbook_longans,max_eval_instances=100", priority: 1}
  {description: "natural_qa:model=text,mode=closedbook,max_eval_instances=100", priority: 1}

  ## Closed-book QA with multiple choice

  # Adaptation method is set to ADAPT_MULTIPLE_CHOICE_SEPARATE_CALIBRATED and echo=True
  {description: "commonsense:model=full_functionality_text,dataset=hellaswag,method=multiple_choice_separate_original,max_eval_instances=100", priority: 1}
  {description: "commonsense:model=full_functionality_text,dataset=openbookqa,method=multiple_choice_separate_calibrated,max_eval_instances=100", priority: 2}
  {description: "truthful_qa:model=text,task=mc_single,max_eval_instances=100", priority: 1}

  {description: "mmlu:model=text,subject=abstract_algebra,max_eval_instances=20", priority: 2}
  {description: "mmlu:model=text,subject=college_chemistry,max_eval_instances=20", priority: 2}
  {description: "mmlu:model=text,subject=computer_security,max_eval_instances=20", priority: 2}
  {description: "mmlu:model=text,subject=econometrics,max_eval_instances=20", priority: 2}
  {description: "mmlu:model=text,subject=us_foreign_policy,max_eval_instances=20", priority: 2}
  
  ##### Information Retrieval #####
  # Scenarios: MS Marco (Regular), MS MARCO (TREC)

  {description: "msmarco:model=full_functionality_text,track=regular,valid_topk=30,max_eval_instances=100", priority: 2}
  {description: "msmarco:model=full_functionality_text,track=trec,valid_topk=30,max_eval_instances=100", priority: 1}

  ##### Summarization #####
  # Scenarios: XSUM, CNN/DM

  {description: "summarization_cnndm:model=text,temperature=0.3,device=cpu,max_eval_instances=100", priority: 1}
  {description: "summarization_xsum_sampled:model=text,temperature=0.3,device=cpu,max_eval_instances=100", priority: 1}


  ##### Sentiment Analysis #####
  # Scenarios: IMDB

  {description: "imdb:model=text,max_eval_instances=100", priority: 1}


  ##### (Miscellaneous) Text Classification #####
  # Scenarios: RAFT

  {description: "raft:subset=ade_corpus_v2,model=text,max_eval_instances=9", priority: 2}
  {description: "raft:subset=banking_77,model=text,max_eval_instances=9", priority: 2}
  {description: "raft:subset=neurips_impact_statement_risks,model=text,max_eval_instances=9", priority: 2}
  {description: "raft:subset=one_stop_english,model=text,max_eval_instances=9", priority: 2}
  {description: "raft:subset=overruling,model=text,max_eval_instances=9", priority: 2}
  {description: "raft:subset=semiconductor_org_types,model=text,max_eval_instances=9", priority: 2}
  {description: "raft:subset=tweet_eval_hate,model=text,max_eval_instances=9", priority: 2}
  {description: "raft:subset=twitter_complaints,model=text,max_eval_instances=9", priority: 2}
  {description: "raft:subset=systematic_review_inclusion,model=text,max_eval_instances=9", priority: 2}
  {description: "raft:subset=tai_safety_research,model=text,max_eval_instances=9", priority: 2}
  {description: "raft:subset=terms_of_service,model=text,max_eval_instances=10", priority: 2}


  ##### Toxicity Detection #####
  # Scenarios: CivilComments

  {description: "civil_comments:model=text,demographic=all,max_eval_instances=11", priority: 1}
  {description: "civil_comments:model=text,demographic=male,max_eval_instances=11", priority: 2}
  {description: "civil_comments:model=text,demographic=female,max_eval_instances=11", priority: 2}
  {description: "civil_comments:model=text,demographic=LGBTQ,max_eval_instances=11", priority: 2}
  {description: "civil_comments:model=text,demographic=christian,max_eval_instances=11", priority: 2}
  {description: "civil_comments:model=text,demographic=muslim,max_eval_instances=11", priority: 2}
  {description: "civil_comments:model=text,demographic=other_religions,max_eval_instances=11", priority: 2}
  {description: "civil_comments:model=text,demographic=black,max_eval_instances=11", priority: 2}
  {description: "civil_comments:model=text,demographic=white,max_eval_instances=12", priority: 2}

]