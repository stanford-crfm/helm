# A minimal example where we compare a few models on a few benchmarks.

entries: [
  {description: "mmlu:subject=philosophy,data_augmentation=canonical,model=openai/davinci", priority: 1}
  {description: "mmlu:subject=philosophy,data_augmentation=canonical,model=openai/text-davinci-002", priority: 1}

  {description: "mmlu:subject=anatomy,data_augmentation=canonical,model=openai/davinci", priority: 1}
  {description: "mmlu:subject=anatomy,data_augmentation=canonical,model=openai/text-davinci-002", priority: 1}

  {description: "boolq:data_augmentation=canonical,model=openai/davinci", priority: 1}
  {description: "boolq:data_augmentation=canonical,model=openai/text-davinci-002", priority: 1}

  {description: "bold:subject=all,model=openai/davinci", priority: 1}
  {description: "bold:subject=all,model=openai/text-davinci-002", priority: 1}
]
