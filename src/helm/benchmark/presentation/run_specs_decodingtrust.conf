# Main `RunSpec`s for the benchmarking.

entries: [
  ##### DecodingTrust Trustworthiness Perspectives #####

  ## Toxicity  #####
  # subject: toxic, non-toxic, gpt-3.5, gpt-4

  {description: "decodingtrust_toxicity_prompts:subject=toxic,model=text", priority=1}
  {description: "decodingtrust_toxicity_prompts:subject=non-toxic,model=text", priority=1}
  {description: "decodingtrust_toxicity_prompts:subject=gpt-3.5,model=text", priority=1}
  {description: "decodingtrust_toxicity_prompts:subject=gpt-4,model=text", priority=1}

  ## Stereotype bias  #####
  # Tasks: all

  {description: "decodingtrust_stereotype_bias:task=all,model=text", priority=1}

  ## Robustness to Adversarial Text Input #####
  # Tasks: SST-2, MNLI, MNLI(-mm), QQP, QNLI, RTE

  {description: "decodingtrust_adv_robustness:task=sst2,model=text", priority=1}
  {description: "decodingtrust_adv_robustness:task=qqp,model=text", priority=1}
  {description: "decodingtrust_adv_robustness:task=mnli,model=text", priority=1}
  {description: "decodingtrust_adv_robustness:task=mnli-mm,model=text", priority=1}
  {description: "decodingtrust_adv_robustness:task=rte,model=text", priority=1}
  {description: "decodingtrust_adv_robustness:task=qnli,model=text", priority=1}

  ## OOD robustness ##
  # Tasks: OOD styles (SST-2)
  {description: "decodingtrust_ood_robustness:ood_type=style,task=shake_w,demo_name=base,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=augment,demo_name=base,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=shake_p0,demo_name=base,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=shake_p0.6,demo_name=base,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=bible_p0,demo_name=base,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=bible_p0.6,demo_name=base,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=romantic_p0,demo_name=base,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=romantic_p0.6,demo_name=base,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=tweet_p0,demo_name=base,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=tweet_p0.6,demo_name=base,model=text", priority=1}

  #Task: OOD in-context demonstrations (style)
  {description: "decodingtrust_ood_robustness:ood_type=style,task=shake_p0.6,demo_name=base,run_id=0,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=shake_p0.6,demo_name=base,run_id=1,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=shake_p0.6,demo_name=base,run_id=2,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=bible_p0.6,demo_name=base,run_id=0,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=bible_p0.6,demo_name=base,run_id=1,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=bible_p0.6,demo_name=base,run_id=2,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=romantic_p0.6,demo_name=base,run_id=0,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=romantic_p0.6,demo_name=base,run_id=1,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=romantic_p0.6,demo_name=base,run_id=2,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=tweet_p0.6,demo_name=base,run_id=0,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=tweet_p0.6,demo_name=base,run_id=1,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=style,task=tweet_p0.6,demo_name=base,run_id=2,model=text", priority=1}

  #Task: OOD knowledge
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2023,demo_name=2021_qa,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2023,demo_name=2021_qa,idk=1,model=text", priority=1}

  #Task: OOD in-context demonstrations (domain)
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=global_facts,run_id=0,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=global_facts,run_id=1,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=global_facts,run_id=2,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=machine_learning,run_id=0,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=machine_learning,run_id=1,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=machine_learning,run_id=2,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=moral_scenarios,run_id=0,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=moral_scenarios,run_id=1,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=moral_scenarios,run_id=2,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=us_foreign_policy,run_id=0,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=us_foreign_policy,run_id=1,model=text", priority=1}
  {description: "decodingtrust_ood_robustness:ood_type=knowledge,task=qa_2020,demo_name=us_foreign_policy,run_id=2,model=text", priority=1}

  ### Robustness against Adversarial Demonstrations ###
  # for counterfactual 
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=snli_premise,demo_name=demo+cf,description=nli3,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=snli_hypothesis,demo_name=demo+cf,description=nli3,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=control_raising,demo_name=demo+cf,description=control_raising,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=irregular_form,demo_name=demo+cf,description=irregular_form,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=main_verb,demo_name=demo+cf,description=main_verb,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=syntactic_category,demo_name=demo+cf,description=syntactic_category,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=snli_premise,demo_name=demo,description=nli3,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=snli_hypothesis,demo_name=demo,description=nli3,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=snli_premise,demo_name=cf,description=nli3,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=snli_hypothesis,demo_name=cf,description=nli3,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=snli_premise,demo_name=zero,description=nli3,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=snli_hypothesis,demo_name=zero,description=nli3,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=control_raising,demo_name=demo,description=control_raising,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=irregular_form,demo_name=demo,description=irregular_form,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=main_verb,demo_name=demo,description=main_verb,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=syntactic_category,demo_name=demo,description=syntactic_category,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=control_raising,demo_name=cf,description=control_raising,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=irregular_form,demo_name=cf,description=irregular_form,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=main_verb,demo_name=cf,description=main_verb,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=syntactic_category,demo_name=cf,description=syntactic_category,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=control_raising,demo_name=zero,description=control_raising,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=irregular_form,demo_name=zero,description=irregular_form,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=main_verb,demo_name=zero,description=main_verb,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=counterfactual,data=syntactic_category,demo_name=zero,description=syntactic_category,model=text", priority=1}
  # for spurious
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=PP,demo_name=entail-bias,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=adverb,demo_name=entail-bias,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=embedded_under_verb,demo_name=entail-bias,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=l_relative_clause,demo_name=entail-bias,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=passive,demo_name=entail-bias,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=s_relative_clause,demo_name=entail-bias,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=PP,demo_name=non-entail-bias,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=adverb,demo_name=non-entail-bias,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=embedded_under_verb,demo_name=non-entail-bias,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=l_relative_clause,demo_name=non-entail-bias,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=passive,demo_name=non-entail-bias,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=s_relative_clause,demo_name=non-entail-bias,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=PP,demo_name=zero,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=adverb,demo_name=zero,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=embedded_under_verb,demo_name=zero,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=l_relative_clause,demo_name=zero,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=passive,demo_name=zero,description=nli2,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=spurious,data=s_relative_clause,demo_name=zero,description=nli2,model=text", priority=1}
  # for backdoor
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup1_badword,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_badword,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_badword,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup1_addsent,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_addsent,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_addsent,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup1_synbkd,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_synbkd,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_synbkd,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup1_stylebkd,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_stylebkd,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_stylebkd,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_cf_first,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_cf_first,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_cf_middle,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_cf_middle,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_cf_end,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup3_cf_end,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_badword_0,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup2_badword_1,description=sa,model=text", priority=1}
  {description: "decodingtrust_adv_demonstration:perspective=backdoor,data=sst-2,demo_name=setup1_badword,description=badword,model=text", priority=1}


  ### Privacy ###
  # Task: privacy understanding 
  
  {description: "decodingtrust_privacy:scenario_name=privacy_understanding,dataset_size=100,prompt_type=1,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=privacy_understanding,dataset_size=100,prompt_type=2,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=privacy_understanding,dataset_size=100,prompt_type=3,model=text", priority=1}
  
  # Task: privacy pii
  {description: "decodingtrust_privacy:scenario_name=pii,data_file=enron_data/five_shot.json,few_shot_num=0,dataset_size=100,prompt_type=attack,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=pii,data_file=enron_data/five_shot.json,few_shot_num=3,dataset_size=100,prompt_type=attack,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=pii,data_file=enron_data/five_shot.json,few_shot_num=3,dataset_size=100,prompt_type=protect,model=text", priority=1}

  # task: train data extraction on enron email
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=context-50,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=context-100,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=context-200,model=text", priority=1}

  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=five-shot-a,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=five-shot-b,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=five-shot-c,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=five-shot-d,model=text", priority=1}

  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=one-shot-a,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=one-shot-b,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=one-shot-c,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=one-shot-d,model=text", priority=1}

  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=knownzero-shot-a,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=knownzero-shot-b,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=knownzero-shot-c,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=knownzero-shot-d,model=text", priority=1}

  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=five-shot-non-domain-a,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=five-shot-non-domain-b,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=five-shot-non-domain-c,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=five-shot-non-domain-d,model=text", priority=1}

  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=one-shot-non-domain-a,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=one-shot-non-domain-b,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=one-shot-non-domain-c,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=one-shot-non-domain-d,model=text", priority=1}

  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=zero-shot-a,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=zero-shot-b,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=zero-shot-c,model=text", priority=1}
  {description: "decodingtrust_privacy:scenario_name=enron_email_extraction,data_file=enron_data,prompt_type=zero-shot-d,model=text", priority=1}


  ### Machine Ethics ###
  # Machine Ethics: evaluation on standard benchmarks
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_short,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=0,model=text", priority=1} # Evaluation on short commonsense morality subset of ETHICS dataset under zero-shot setting
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_short,max_train_instances=32,jailbreak_prompt=0,evasive_sentence=0,model=text", priority=1} # Evaluation on short commonsense morality subset of ETHICS dataset under few-shot setting
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_long,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=0,model=text", priority=1} # Evaluation on long commonsense morality subset of ETHICS dataset under zero-shot setting
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_long,max_train_instances=8,jailbreak_prompt=0,evasive_sentence=0,model=text", priority=1} # Evaluation on long commonsense morality subset of ETHICS dataset under few-shot setting
  {description: "decodingtrust_machine_ethics:data_name=jiminy,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=0,model=text", priority=1} # Evaluation on Jiminy Cricket dataset under zero-shot setting
  {description: "decodingtrust_machine_ethics:data_name=jiminy,max_train_instances=3,jailbreak_prompt=0,evasive_sentence=0,model=text", priority=1} # Evaluation on Jiminy Cricket dataset under few-shot setting
  
  # Machine Ethics: evaluation on jailbreaking prompts
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_short,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=1,evasive_sentence=0,model=text", priority=1} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_short,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=2,evasive_sentence=0,model=text", priority=1} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_short,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=3,evasive_sentence=0,model=text", priority=1} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_short,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=4,evasive_sentence=0,model=text", priority=1} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_short,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=5,evasive_sentence=0,model=text", priority=1} # Evaluation on jailbreaking prompts on ETHICS dataset
  
  {description: "decodingtrust_machine_ethics:data_name=jiminy,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=1,evasive_sentence=0,model=text", priority=1} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "decodingtrust_machine_ethics:data_name=jiminy,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=2,evasive_sentence=0,model=text", priority=1} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "decodingtrust_machine_ethics:data_name=jiminy,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=3,evasive_sentence=0,model=text", priority=1} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "decodingtrust_machine_ethics:data_name=jiminy,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=4,evasive_sentence=0,model=text", priority=1} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "decodingtrust_machine_ethics:data_name=jiminy,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=5,evasive_sentence=0,model=text", priority=1} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  
  # Machine Ethics: evaluation on evasive sentences
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_short,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=1,model=text", priority=1} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_short,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=2,model=text", priority=1} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_short,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=3,model=text", priority=1} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_short,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=4,model=text", priority=1} # Evaluation on jailbreaking prompts on ETHICS dataset
  {description: "decodingtrust_machine_ethics:data_name=ethics_commonsense_short,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=5,model=text", priority=1} # Evaluation on jailbreaking prompts on ETHICS dataset
  
  {description: "decodingtrust_machine_ethics:data_name=jiminy,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=1,model=text", priority=1} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "decodingtrust_machine_ethics:data_name=jiminy,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=2,model=text", priority=1} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "decodingtrust_machine_ethics:data_name=jiminy,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=3,model=text", priority=1} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "decodingtrust_machine_ethics:data_name=jiminy,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=4,model=text", priority=1} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset
  {description: "decodingtrust_machine_ethics:data_name=jiminy,max_eval_instances=200,max_train_instances=0,jailbreak_prompt=0,evasive_sentence=5,model=text", priority=1} # Evaluation on jailbreaking prompts on Jiminy Cricket dataset


  ### Fairness ###
  # Fairness: evaluation in zero-shot setting
  {description: "decodingtrust_fairness:task=predict_annual_income,train_base_rate=0.0,test_base_rate=0.0,num_train=0,num_test=200,model=text", priority=1} # evaluation in zero-shot setting on test sets with base rate parity difference 0.0
  {description: "decodingtrust_fairness:task=predict_annual_income,train_base_rate=0.0,test_base_rate=0.5,num_train=0,num_test=200,model=text", priority=1} # evaluation in zero-shot setting on test sets with base rate parity difference 0.5
  {description: "decodingtrust_fairness:task=predict_annual_income,train_base_rate=0.0,test_base_rate=1.0,num_train=0,num_test=200,model=text", priority=1} # evaluation in zero-shot setting on test sets with base rate parity difference 1.0

  # Fairness: evaluation in few-shot setting with different demographically imbalanced context
  {description: "decodingtrust_fairness:task=predict_annual_income,train_base_rate=0.0,test_base_rate=0.0,num_train=32,num_test=200,model=text", priority=1} # evaluation in few-shot setting with context of base rate parity difference 0.0
  {description: "decodingtrust_fairness:task=predict_annual_income,train_base_rate=0.5,test_base_rate=0.0,num_train=32,num_test=200,model=text", priority=1} # evaluation in few-shot setting with context of base rate parity difference 0.5
  {description: "decodingtrust_fairness:task=predict_annual_income,train_base_rate=1.0,test_base_rate=0.0,num_train=32,num_test=200,model=text", priority=1} # evaluation in few-shot setting with context of base rate parity difference 1.0

  # Fairness: evaluation in few-shot setting with different numbers of fair few-shot examples
  {description: "decodingtrust_fairness:task=predict_annual_income,train_base_rate=0.0,test_base_rate=0.5,num_train=0,num_test=200,model=text", priority=1} # evaluation in few-shot setting with context of 0 fair few-shot examples
  {description: "decodingtrust_fairness:task=predict_annual_income,train_base_rate=0.0,test_base_rate=0.5,num_train=16,num_test=200,model=text", priority=1} # evaluation in few-shot setting with context of 16 fair few-shot examples
  {description: "decodingtrust_fairness:task=predict_annual_income,train_base_rate=0.0,test_base_rate=0.5,num_train=32,num_test=200,model=text", priority=1} # evaluation in few-shot setting with context of 32 fair few-shot examples
]
