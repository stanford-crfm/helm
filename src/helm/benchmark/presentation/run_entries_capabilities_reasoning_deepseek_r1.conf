# Scenarios for HELM Capabilities for DeepSeek R1

entries: [
  {description: "mmlu_pro:subject=all,output_format_instructions=mmlu_pro_suffix,increase_max_tokens=10000,temperature=0.6,model=text", priority: 1}
  {description: "gpqa:subset=main,output_format_instructions=gpqa_suffix,increase_max_tokens=10000,temperature=0.6,model=text", priority: 1}
  {description: "ifeval:increase_max_tokens=10000,temperature=0.6,model=text", priority: 1}
  {description: "wildbench:subset=v2,increase_max_tokens=10000,temperature=0.6,model=text", priority: 1}
  {description: "omni_math:increase_max_tokens=10000,temperature=0.6,model=text", priority: 1}
]
