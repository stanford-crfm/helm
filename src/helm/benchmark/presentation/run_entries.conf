# Main `RunSpec`s for the benchmarking.

entries: [
  ##### Generic #####

  ##### Question Answering #####
  # Scenarios: BoolQ, NarrativeQA, NewsQA, QuAC
  # Scenarios: NaturalQuestions
  # Scenarios: CommonsenseQA, HellaSwag, OpenBookQA, TruthfulQA
  # Scenarios: MMLU

  ## Reading comprehension

  {description: "boolq:model=text,data_augmentation=canonical", priority: 1}
  {description: "narrative_qa:model=text,data_augmentation=canonical", priority: 2}
  {description: "news_qa:model=text,data_augmentation=canonical", priority: 3}
  {description: "quac:model=text,data_augmentation=canonical", priority: 1}

  ## Reading comprehension and closedbook QA variants

  {description: "natural_qa:model=text,mode=openbook_longans,data_augmentation=canonical", priority: 1}
  {description: "natural_qa:model=text,mode=closedbook,data_augmentation=canonical", priority: 1}

  ## Closed-book QA with multiple choice

  {description: "commonsense:model=text,dataset=commonsenseqa,method=multiple_choice_separate_calibrated,data_augmentation=canonical", priority: 3}
  # Adaptation method is set to ADAPT_MULTIPLE_CHOICE_SEPARATE_CALIBRATED and echo=True
  {description: "commonsense:model=full_functionality_text,dataset=hellaswag,method=multiple_choice_separate_original,data_augmentation=canonical", priority: 1}
  {description: "commonsense:model=full_functionality_text,dataset=openbookqa,method=multiple_choice_separate_calibrated,data_augmentation=canonical", priority: 2}
  {description: "truthful_qa:model=text,task=mc_single,data_augmentation=canonical", priority: 1}

  {description: "mmlu:model=text,subject=abstract_algebra,data_augmentation=canonical", priority: 2}
  {description: "mmlu:model=text,subject=anatomy,data_augmentation=canonical", priority: 3}
  {description: "mmlu:model=text,subject=college_chemistry,data_augmentation=canonical", priority: 2}
  {description: "mmlu:model=text,subject=computer_security,data_augmentation=canonical", priority: 2}
  {description: "mmlu:model=text,subject=econometrics,data_augmentation=canonical", priority: 2}
  {description: "mmlu:model=text,subject=global_facts,data_augmentation=canonical", priority: 3}
  {description: "mmlu:model=text,subject=jurisprudence,data_augmentation=canonical", priority: 3}
  {description: "mmlu:model=text,subject=philosophy,data_augmentation=canonical", priority: 3}
  {description: "mmlu:model=text,subject=professional_medicine,data_augmentation=canonical", priority: 3}
  {description: "mmlu:model=text,subject=us_foreign_policy,data_augmentation=canonical", priority: 2}
  {description: "mmlu:model=text,subject=astronomy,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=business_ethics,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=clinical_knowledge,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=college_biology,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=college_computer_science,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=college_mathematics,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=college_medicine,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=college_physics,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=conceptual_physics,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=electrical_engineering,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=elementary_mathematics,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=formal_logic,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_biology,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_chemistry,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_computer_science,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_european_history,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_geography,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_government_and_politics,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_macroeconomics,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_mathematics,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_microeconomics,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_physics,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_psychology,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_statistics,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_us_history,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=high_school_world_history,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=human_aging,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=human_sexuality,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=international_law,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=logical_fallacies,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=machine_learning,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=management,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=marketing,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=medical_genetics,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=miscellaneous,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=moral_disputes,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=moral_scenarios,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=nutrition,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=prehistory,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=professional_accounting,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=professional_law,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=professional_psychology,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=public_relations,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=security_studies,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=sociology,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=virology,data_augmentation=canonical", priority: 4}
  {description: "mmlu:model=text,subject=world_religions,data_augmentation=canonical", priority: 4}


  ##### Information Retrieval #####
  # Scenarios: MS Marco (Regular), MS MARCO (TREC)

  {description: "msmarco:model=full_functionality_text,data_augmentation=canonical,track=regular,valid_topk=30", priority: 2}
  {description: "msmarco:model=full_functionality_text,data_augmentation=canonical,track=trec,valid_topk=30", priority: 1}

  ##### Summarization #####
  # Scenarios: XSUM, CNN/DM

  {description: "summarization_cnndm:model=text,temperature=0.3,device=cpu", priority: 1}
  {description: "summarization_xsum_sampled:model=text,temperature=0.3,device=cpu", priority: 1}


  ##### Sentiment Analysis #####
  # Scenarios: IMDB

  {description: "imdb:model=text,data_augmentation=canonical", priority: 1}


  ##### (Miscellaneous) Text Classification #####
  # Scenarios: RAFT

  {description: "raft:subset=ade_corpus_v2,model=text,data_augmentation=canonical", priority: 2}
  {description: "raft:subset=banking_77,model=text,data_augmentation=canonical", priority: 2}
  {description: "raft:subset=neurips_impact_statement_risks,model=text,data_augmentation=canonical", priority: 2}
  {description: "raft:subset=one_stop_english,model=text,data_augmentation=canonical", priority: 2}
  {description: "raft:subset=overruling,model=text,data_augmentation=canonical", priority: 2}
  {description: "raft:subset=semiconductor_org_types,model=text,data_augmentation=canonical", priority: 2}
  {description: "raft:subset=tweet_eval_hate,model=text,data_augmentation=canonical", priority: 2}
  {description: "raft:subset=twitter_complaints,model=text,data_augmentation=canonical", priority: 2}
  {description: "raft:subset=systematic_review_inclusion,model=text,data_augmentation=canonical", priority: 2}
  {description: "raft:subset=tai_safety_research,model=text,data_augmentation=canonical", priority: 2}
  {description: "raft:subset=terms_of_service,model=text,data_augmentation=canonical", priority: 2}


  ##### Toxicity Detection #####
  # Scenarios: CivilComments

  {description: "civil_comments:model=text,demographic=all,data_augmentation=canonical", priority: 1}
  {description: "civil_comments:model=text,demographic=male,data_augmentation=canonical", priority: 2}
  {description: "civil_comments:model=text,demographic=female,data_augmentation=canonical", priority: 2}
  {description: "civil_comments:model=text,demographic=LGBTQ,data_augmentation=canonical", priority: 2}
  {description: "civil_comments:model=text,demographic=christian,data_augmentation=canonical", priority: 2}
  {description: "civil_comments:model=text,demographic=muslim,data_augmentation=canonical", priority: 2}
  {description: "civil_comments:model=text,demographic=other_religions,data_augmentation=canonical", priority: 2}
  {description: "civil_comments:model=text,demographic=black,data_augmentation=canonical", priority: 2}
  {description: "civil_comments:model=text,demographic=white,data_augmentation=canonical", priority: 2}

  ##### Machine Translation #####
  # Scenarios: WMT_14

  {description: "wmt_14:language_pair=en-cs,model=text", priority: 3}
  {description: "wmt_14:language_pair=en-de,model=text", priority: 3}
  {description: "wmt_14:language_pair=en-fr,model=text", priority: 3}
  {description: "wmt_14:language_pair=en-hi,model=text", priority: 3}
  {description: "wmt_14:language_pair=en-ru,model=text", priority: 3}
  {description: "wmt_14:language_pair=cs-en,model=text", priority: 3}
  {description: "wmt_14:language_pair=de-en,model=text", priority: 3}
  {description: "wmt_14:language_pair=fr-en,model=text", priority: 3}
  {description: "wmt_14:language_pair=hi-en,model=text", priority: 3}
  {description: "wmt_14:language_pair=ru-en,model=text", priority: 3}


  ##### Component Skills and Risks #####

  ##### Language #####
  # Scenarios: BLiMP, The Pile, ICE, WikiText-103, TwitterAAE

  # We select 4 phenomena to elevate to priority 2, one per linguistic field.
  # The phenomena in BLiMP are annotated belong to one of the following 4 linguistic fields:
  # Morphology, Semantics, Syntax, and Syntax-Semantics
  # Beyond ensuring coverage of these 4 fields, to choose the higher priority representative,
  # we choose the phenomena within the field with the lowest GPT-2 performance reported (Warsadt et al., 2020).
  {description: "blimp:model=full_functionality_text,phenomenon=anaphor_agreement", priority: 3} # Morphology
  {description: "blimp:model=full_functionality_text,phenomenon=determiner_noun_agreement", priority: 3} # Morphology
  {description: "blimp:model=full_functionality_text,phenomenon=irregular_forms", priority: 2} # Morphology
  {description: "blimp:model=full_functionality_text,phenomenon=subject_verb_agreement", priority: 3} # Morphology
  {description: "blimp:model=full_functionality_text,phenomenon=quantifiers", priority: 2} # Semantics
  {description: "blimp:model=full_functionality_text,phenomenon=npi_licensing", priority: 3} # Semantics
  {description: "blimp:model=full_functionality_text,phenomenon=argument_structure", priority: 3} # Syntax
  {description: "blimp:model=full_functionality_text,phenomenon=ellipsis", priority: 3} # Syntax
  {description: "blimp:model=full_functionality_text,phenomenon=filler_gap_dependency", priority: 3} # Syntax
  {description: "blimp:model=full_functionality_text,phenomenon=island_effects", priority: 2} # Syntax
  {description: "blimp:model=full_functionality_text,phenomenon=binding", priority: 2} # Syntax-Semantics
  {description: "blimp:model=full_functionality_text,phenomenon=control_raising", priority: 3} # Syntax-Semantics

  ## Language modeling
  {description: "wikitext_103:model=full_functionality_text", priority: 3}

  {description: "the_pile:model=full_functionality_text,subset=ArXiv", priority: 2}
  {description: "the_pile:model=full_functionality_text,subset=BookCorpus2", priority: 2}
  {description: "the_pile:model=full_functionality_text,subset=Books3", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=DM Mathematics", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=Enron Emails", priority: 2}
  {description: "the_pile:model=full_functionality_text,subset=EuroParl", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=FreeLaw", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=Github", priority: 2}
  {description: "the_pile:model=full_functionality_text,subset=Gutenberg (PG-19)", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=HackerNews", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=NIH ExPorter", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=OpenSubtitles", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=OpenWebText2", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=PhilPapers", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=Pile-CC", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=PubMed Abstracts", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=PubMed Central", priority: 2}
  {description: "the_pile:model=full_functionality_text,subset=StackExchange", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=USPTO Backgrounds", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=Ubuntu IRC", priority: 3}
  {description: "the_pile:model=full_functionality_text,subset=Wikipedia (en)", priority: 2}
  {description: "the_pile:model=full_functionality_text,subset=YoutubeSubtitles", priority: 3}

  {description: "twitter_aae:model=full_functionality_text,demographic=aa", priority: 1}
  {description: "twitter_aae:model=full_functionality_text,demographic=white", priority: 1}

  {description: "ice:model=full_functionality_text,subset=can", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ea", priority: 2}
  {description: "ice:model=full_functionality_text,subset=hk", priority: 2}
  {description: "ice:model=full_functionality_text,subset=ind", priority: 2}
  {description: "ice:model=full_functionality_text,subset=ja", priority: 3}
  {description: "ice:model=full_functionality_text,subset=phi", priority: 3}
  {description: "ice:model=full_functionality_text,subset=sin", priority: 3}
  {description: "ice:model=full_functionality_text,subset=usa", priority: 2}

  # split by text category
  {description: "ice:model=full_functionality_text,subset=can,category=S1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=can,category=S2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=can,category=W1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=can,category=W2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ea,category=S1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ea,category=S2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ea,category=W1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ea,category=W2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=hk,category=S1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=hk,category=S2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=hk,category=W1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=hk,category=W2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ind,category=S1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ind,category=S2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ind,category=W1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ind,category=W2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ja,category=S1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ja,category=S2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ja,category=W1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=ja,category=W2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=phi,category=S1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=phi,category=S2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=phi,category=W1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=phi,category=W2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=sin,category=S1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=sin,category=S2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=sin,category=W1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=sin,category=W2", priority: 3}
  {description: "ice:model=full_functionality_text,subset=usa,category=W1", priority: 3}
  {description: "ice:model=full_functionality_text,subset=usa,category=W2", priority: 3}
  {description: "ice:model=full_functionality_text,category=S", priority: 3}
  {description: "ice:model=full_functionality_text,category=W", priority: 3}

  {description: "ice:model=full_functionality_text,gender=female", priority: 2}
  {description: "ice:model=full_functionality_text,gender=male", priority: 2}

  ##### Knowledge #####

  # For WikiFact, we sampled the following 10 relation types, which cover diverse topics
  # across general facts, humanities, social sciences and STEM.
  {description: "wikifact:model=text,k=5,subject=plaintiff", priority: 2}
  {description: "wikifact:model=text,k=5,subject=place_of_birth", priority: 2}
  {description: "wikifact:model=text,k=5,subject=medical_condition_treated", priority: 2}
  {description: "wikifact:model=text,k=5,subject=instance_of", priority: 2}
  {description: "wikifact:model=text,k=5,subject=part_of", priority: 2}
  {description: "wikifact:model=text,k=5,subject=currency", priority: 2}
  {description: "wikifact:model=text,k=5,subject=position_held", priority: 2}
  {description: "wikifact:model=text,k=5,subject=author", priority: 2}
  {description: "wikifact:model=text,k=5,subject=discoverer_or_inventor", priority: 2}
  {description: "wikifact:model=text,k=5,subject=symptoms_and_signs", priority: 2}
  {description: "wikifact:model=text,k=5,subject=applies_to_jurisdiction", priority: 4}
  {description: "wikifact:model=text,k=5,subject=field_of_work", priority: 4}
  {description: "wikifact:model=text,k=5,subject=member_of_political_party", priority: 4}
  {description: "wikifact:model=text,k=5,subject=native_language", priority: 4}
  {description: "wikifact:model=text,k=5,subject=occupation", priority: 4}
  {description: "wikifact:model=text,k=5,subject=employer", priority: 4}
  {description: "wikifact:model=text,k=5,subject=atomic_number", priority: 4}
  {description: "wikifact:model=text,k=5,subject=measured_physical_quantity", priority: 4}
  {description: "wikifact:model=text,k=5,subject=solved_by", priority: 4}
  {description: "wikifact:model=text,k=5,subject=number_of_processor_cores", priority: 4}
  {description: "wikifact:model=text,k=5,subject=file_extension", priority: 4}
  {description: "wikifact:model=text,k=5,subject=basic_form_of_government", priority: 4}
  {description: "wikifact:model=text,k=5,subject=owned_by", priority: 4}
  {description: "wikifact:model=text,k=5,subject=instrument", priority: 4}
  {description: "wikifact:model=text,k=5,subject=central_bank", priority: 4}
  {description: "wikifact:model=text,k=5,subject=located_in_the_administrative_territorial_entity", priority: 4}
  {description: "wikifact:model=text,k=5,subject=office_held_by_head_of_government", priority: 4}
  {description: "wikifact:model=text,k=5,subject=movement", priority: 4}
  {description: "wikifact:model=text,k=5,subject=genre", priority: 4}
  {description: "wikifact:model=text,k=5,subject=capital_of", priority: 4}
  {description: "wikifact:model=text,k=5,subject=named_after", priority: 4}
  {description: "wikifact:model=text,k=5,subject=religion", priority: 4}
  {description: "wikifact:model=text,k=5,subject=languages_spoken_written_or_signed", priority: 4}
  {description: "wikifact:model=text,k=5,subject=headquarters_location", priority: 4}
  {description: "wikifact:model=text,k=5,subject=defendant", priority: 4}
  {description: "wikifact:model=text,k=5,subject=award_received", priority: 4}
  {description: "wikifact:model=text,k=5,subject=country", priority: 4}
  {description: "wikifact:model=text,k=5,subject=creator", priority: 4}
  {description: "wikifact:model=text,k=5,subject=manufacturer", priority: 4}
  {description: "wikifact:model=text,k=5,subject=developer", priority: 4}
  {description: "wikifact:model=text,k=5,subject=location_of_discovery", priority: 4}
  {description: "wikifact:model=text,k=5,subject=twinned_administrative_body", priority: 4}
  {description: "wikifact:model=text,k=5,subject=office_held_by_head_of_state", priority: 4}
  {description: "wikifact:model=text,k=5,subject=participating_team", priority: 4}
  {description: "wikifact:model=text,k=5,subject=place_of_death", priority: 4}
  {description: "wikifact:model=text,k=5,subject=drug_or_therapy_used_for_treatment", priority: 4}
  {description: "wikifact:model=text,k=5,subject=genetic_association", priority: 4}
  {description: "wikifact:model=text,k=5,subject=statement_describes", priority: 4}
  {description: "wikifact:model=text,k=5,subject=repealed_by", priority: 4}
  {description: "wikifact:model=text,k=5,subject=record_label", priority: 4}
  {description: "wikifact:model=text,k=5,subject=country_of_citizenship", priority: 4}
  {description: "wikifact:model=text,k=5,subject=location", priority: 4}
  {description: "wikifact:model=text,k=5,subject=programming_language", priority: 4}
  {description: "wikifact:model=text,k=5,subject=subclass_of", priority: 4}
  {description: "wikifact:model=text,k=5,subject=continent", priority: 4}
  {description: "wikifact:model=text,k=5,subject=laws_applied", priority: 4}
  {description: "wikifact:model=text,k=5,subject=operating_system", priority: 4}
  {description: "wikifact:model=text,k=5,subject=head_of_state", priority: 4}
  {description: "wikifact:model=text,k=5,subject=subsidiary", priority: 4}
  {description: "wikifact:model=text,k=5,subject=capital", priority: 4}
  {description: "wikifact:model=text,k=5,subject=original_language_of_film_or_TV_show", priority: 4}
  {description: "wikifact:model=text,k=5,subject=official_language", priority: 4}
  {description: "wikifact:model=text,k=5,subject=overrules", priority: 4}
  {description: "wikifact:model=text,k=5,subject=therapeutic_area", priority: 4}
  {description: "wikifact:model=text,k=5,subject=language_of_work_or_name", priority: 4}
  {description: "wikifact:model=text,k=5,subject=position_played_on_team", priority: 4}
  {description: "wikifact:model=text,k=5,subject=stock_exchange", priority: 4}
  {description: "wikifact:model=text,k=5,subject=original_network", priority: 4}
  {description: "wikifact:model=text,k=5,subject=industry", priority: 4}
  {description: "wikifact:model=text,k=5,subject=member_of", priority: 4}
  {description: "wikifact:model=text,k=5,subject=shares_border_with", priority: 4}
  {description: "wikifact:model=text,k=5,subject=country_of_origin", priority: 4}
  {description: "wikifact:model=text,k=5,subject=has_part", priority: 4}
  {description: "wikifact:model=text,k=5,subject=diplomatic_relation", priority: 4}
  {description: "wikifact:model=text,k=5,subject=member_of_sports_team", priority: 4}
  {description: "wikifact:model=text,k=5,subject=director", priority: 4}
  {description: "wikifact:model=text,k=5,subject=time_of_discovery_or_invention", priority: 4}
  {description: "wikifact:model=text,k=5,subject=majority_opinion_by", priority: 4}
  {description: "wikifact:model=text,k=5,subject=head_of_government", priority: 4}
  {description: "wikifact:model=text,k=5,subject=educated_at", priority: 4}
  {description: "wikifact:model=text,k=5,subject=influenced_by", priority: 4}
  {description: "wikifact:model=text,k=5,subject=location_of_formation", priority: 4}
  {description: "wikifact:model=text,k=5,subject=electron_configuration", priority: 4}
  {description: "wikifact:model=text,k=5,subject=recommended_unit_of_measurement", priority: 4}
  {description: "wikifact:model=text,k=5,subject=composer", priority: 4}
  {description: "wikifact:model=text,k=5,subject=work_location", priority: 4}



  ##### Reasoning #####

  # Code models outperform text models on reasoning tasks. 
  # Evaluate all language models (model=text_code) on reasoning scenarios.

  ## Synthetic
  # TODO: had to disable these due to a refactor
  # {description: "numeracy:model=text_code,run_solver=True,relation_type=linear,mode=function", priority: 2}
  # {description: "numeracy:model=text_code,run_solver=True,relation_type=plane,mode=function", priority: 3}

  # The DistanceMetric is slow to compute for relation_type 'parabola' and 'paraboloid', so set run_solver=False
  # {description: "numeracy:model=text_code,run_solver=False,relation_type=parabola,mode=function", priority: 4}
  # {description: "numeracy:model=text_code,run_solver=False,relation_type=paraboloid,mode=function", priority: 4}

  {description: "synthetic_reasoning:model=text_code,mode=pattern_match", priority: 2}
  {description: "synthetic_reasoning:model=text_code,mode=variable_substitution", priority: 2}
  {description: "synthetic_reasoning:model=text_code,mode=induction", priority: 2}

  {description: "synthetic_reasoning_natural:model=text_code,difficulty=easy", priority: 2}
  {description: "synthetic_reasoning_natural:model=text_code,difficulty=hard", priority: 2}

  {description: "babi_qa:model=text_code,task=all", priority: 2}
  {description: "babi_qa:model=text_code,task=1", priority: 3}
  {description: "babi_qa:model=text_code,task=2", priority: 4}
  {description: "babi_qa:model=text_code,task=3", priority: 2}
  {description: "babi_qa:model=text_code,task=4", priority: 3}
  {description: "babi_qa:model=text_code,task=5", priority: 4}
  {description: "babi_qa:model=text_code,task=6", priority: 4}
  {description: "babi_qa:model=text_code,task=7", priority: 4}
  {description: "babi_qa:model=text_code,task=8", priority: 4}
  {description: "babi_qa:model=text_code,task=9", priority: 4}
  {description: "babi_qa:model=text_code,task=10", priority: 4}
  {description: "babi_qa:model=text_code,task=11", priority: 4}
  {description: "babi_qa:model=text_code,task=12", priority: 4}
  {description: "babi_qa:model=text_code,task=13", priority: 4}
  {description: "babi_qa:model=text_code,task=14", priority: 4}
  {description: "babi_qa:model=text_code,task=15", priority: 2}
  {description: "babi_qa:model=text_code,task=16", priority: 4}
  {description: "babi_qa:model=text_code,task=17", priority: 4}
  {description: "babi_qa:model=text_code,task=18", priority: 4}
  {description: "babi_qa:model=text_code,task=19", priority: 2}
  {description: "babi_qa:model=text_code,task=20", priority: 4}

  {description: "dyck_language:model=text_code,num_parenthesis_pairs=2", priority: 4}
  {description: "dyck_language:model=text_code,num_parenthesis_pairs=3", priority: 2}
  {description: "dyck_language:model=text_code,num_parenthesis_pairs=4", priority: 4}

  ## Real

  {description: "math:model=text_code,subject=number_theory,level=1,use_official_examples=True", priority: 2}
  {description: "math:model=text_code,subject=intermediate_algebra,level=1,use_official_examples=True", priority: 2}
  {description: "math:model=text_code,subject=algebra,level=1,use_official_examples=True", priority: 2}
  {description: "math:model=text_code,subject=prealgebra,level=1,use_official_examples=True", priority: 2}
  {description: "math:model=text_code,subject=geometry,level=1,use_official_examples=True", priority: 2}
  {description: "math:model=text_code,subject=counting_and_probability,level=1,use_official_examples=True", priority: 2}
  {description: "math:model=text_code,subject=precalculus,level=1,use_official_examples=True", priority: 2}

  {description: "math:model=text_code,subject=number_theory,level=2,use_official_examples=True", priority: 4}
  {description: "math:model=text_code,subject=intermediate_algebra,level=2,use_official_examples=True", priority: 4}
  {description: "math:model=text_code,subject=algebra,level=2,use_official_examples=True", priority: 4}
  {description: "math:model=text_code,subject=prealgebra,level=2,use_official_examples=True", priority: 4}
  {description: "math:model=text_code,subject=geometry,level=2,use_official_examples=True", priority: 4}
  {description: "math:model=text_code,subject=counting_and_probability,level=2,use_official_examples=True", priority: 4}
  {description: "math:model=text_code,subject=precalculus,level=2,use_official_examples=True", priority: 4}

  {description: "math:model=text_code,subject=number_theory,level=3,use_official_examples=True", priority: 3}
  {description: "math:model=text_code,subject=intermediate_algebra,level=3,use_official_examples=True", priority: 3}
  {description: "math:model=text_code,subject=algebra,level=3,use_official_examples=True", priority: 3}
  {description: "math:model=text_code,subject=prealgebra,level=3,use_official_examples=True", priority: 3}
  {description: "math:model=text_code,subject=geometry,level=3,use_official_examples=True", priority: 3}
  {description: "math:model=text_code,subject=counting_and_probability,level=3,use_official_examples=True", priority: 3}
  {description: "math:model=text_code,subject=precalculus,level=3,use_official_examples=True", priority: 3}

  {description: "math:model=text_code,subject=number_theory,level=4,use_official_examples=True", priority: 4}
  {description: "math:model=text_code,subject=intermediate_algebra,level=4,use_official_examples=True", priority: 4}
  {description: "math:model=text_code,subject=algebra,level=4,use_official_examples=True", priority: 4}
  {description: "math:model=text_code,subject=prealgebra,level=4,use_official_examples=True", priority: 4}
  {description: "math:model=text_code,subject=geometry,level=4,use_official_examples=True", priority: 4}
  {description: "math:model=text_code,subject=counting_and_probability,level=4,use_official_examples=True", priority: 4}
  {description: "math:model=text_code,subject=precalculus,level=4,use_official_examples=True", priority: 4}

  {description: "math:model=text_code,subject=number_theory,level=5,use_official_examples=True", priority: 3}
  {description: "math:model=text_code,subject=intermediate_algebra,level=5,use_official_examples=True", priority: 3}
  {description: "math:model=text_code,subject=algebra,level=5,use_official_examples=True", priority: 3}
  {description: "math:model=text_code,subject=prealgebra,level=5,use_official_examples=True", priority: 3}
  {description: "math:model=text_code,subject=geometry,level=5,use_official_examples=True", priority: 3}
  {description: "math:model=text_code,subject=counting_and_probability,level=5,use_official_examples=True", priority: 3}
  {description: "math:model=text_code,subject=precalculus,level=5,use_official_examples=True", priority: 3}

  # With chain-of-thought prompting:
  {description: "math:model=text_code,subject=number_theory,level=1,use_chain_of_thought=True", priority: 2}
  {description: "math:model=text_code,subject=intermediate_algebra,level=1,use_chain_of_thought=True", priority: 2}
  {description: "math:model=text_code,subject=algebra,level=1,use_chain_of_thought=True", priority: 2}
  {description: "math:model=text_code,subject=prealgebra,level=1,use_chain_of_thought=True", priority: 2}
  {description: "math:model=text_code,subject=geometry,level=1,use_chain_of_thought=True", priority: 2}
  {description: "math:model=text_code,subject=counting_and_probability,level=1,use_chain_of_thought=True", priority: 2}
  {description: "math:model=text_code,subject=precalculus,level=1,use_chain_of_thought=True", priority: 2}

  {description: "math:model=text_code,subject=number_theory,level=2,use_chain_of_thought=True", priority: 4}
  {description: "math:model=text_code,subject=intermediate_algebra,level=2,use_chain_of_thought=True", priority: 4}
  {description: "math:model=text_code,subject=algebra,level=2,use_chain_of_thought=True", priority: 4}
  {description: "math:model=text_code,subject=prealgebra,level=2,use_chain_of_thought=True", priority: 4}
  {description: "math:model=text_code,subject=geometry,level=2,use_chain_of_thought=True", priority: 4}
  {description: "math:model=text_code,subject=counting_and_probability,level=2,use_chain_of_thought=True", priority: 4}
  {description: "math:model=text_code,subject=precalculus,level=2,use_chain_of_thought=True", priority: 4}

  {description: "math:model=text_code,subject=number_theory,level=3,use_chain_of_thought=True", priority: 3}
  {description: "math:model=text_code,subject=intermediate_algebra,level=3,use_chain_of_thought=True", priority: 3}
  {description: "math:model=text_code,subject=algebra,level=3,use_chain_of_thought=True", priority: 3}
  {description: "math:model=text_code,subject=prealgebra,level=3,use_chain_of_thought=True", priority: 3}
  {description: "math:model=text_code,subject=geometry,level=3,use_chain_of_thought=True", priority: 3}
  {description: "math:model=text_code,subject=counting_and_probability,level=3,use_chain_of_thought=True", priority: 3}
  {description: "math:model=text_code,subject=precalculus,level=3,use_chain_of_thought=True", priority: 3}

  {description: "math:model=text_code,subject=number_theory,level=4,use_chain_of_thought=True", priority: 4}
  {description: "math:model=text_code,subject=intermediate_algebra,level=4,use_chain_of_thought=True", priority: 4}
  {description: "math:model=text_code,subject=algebra,level=4,use_chain_of_thought=True", priority: 4}
  {description: "math:model=text_code,subject=prealgebra,level=4,use_chain_of_thought=True", priority: 4}
  {description: "math:model=text_code,subject=geometry,level=4,use_chain_of_thought=True", priority: 4}
  {description: "math:model=text_code,subject=counting_and_probability,level=4,use_chain_of_thought=True", priority: 4}
  {description: "math:model=text_code,subject=precalculus,level=4,use_chain_of_thought=True", priority: 4}

  {description: "math:model=text_code,subject=number_theory,level=5,use_chain_of_thought=True", priority: 3}
  {description: "math:model=text_code,subject=intermediate_algebra,level=5,use_chain_of_thought=True", priority: 3}
  {description: "math:model=text_code,subject=algebra,level=5,use_chain_of_thought=True", priority: 3}
  {description: "math:model=text_code,subject=prealgebra,level=5,use_chain_of_thought=True", priority: 3}
  {description: "math:model=text_code,subject=geometry,level=5,use_chain_of_thought=True", priority: 3}
  {description: "math:model=text_code,subject=counting_and_probability,level=5,use_chain_of_thought=True", priority: 3}
  {description: "math:model=text_code,subject=precalculus,level=5,use_chain_of_thought=True", priority: 3}

  {description: "gsm:model=text_code", priority: 2}

  # Legal reasoning
  {description: "legal_support:model=text_code", priority: 2}

  {description: "lsat_qa:model=text_code,task=all", priority: 2}
  {description: "lsat_qa:model=text_code,task=grouping", priority: 3}
  {description: "lsat_qa:model=text_code,task=ordering", priority: 3}
  {description: "lsat_qa:model=text_code,task=assignment", priority: 3}
  {description: "lsat_qa:model=text_code,task=miscellaneous", priority: 3}

  {description: "lextreme:subset=brazilian_court_decisions_judgment,model=text", priority: 5}
  {description: "lextreme:subset=brazilian_court_decisions_unanimity,model=text", priority: 5}
  {description: "lextreme:subset=german_argument_mining,model=text", priority: 5}
  {description: "lextreme:subset=greek_legal_code_chapter,model=text", priority: 5}
  {description: "lextreme:subset=greek_legal_code_subject,model=text", priority: 5}
  {description: "lextreme:subset=greek_legal_code_volume,model=text", priority: 5}
  {description: "lextreme:subset=swiss_judgment_prediction,model=text", priority: 5}
  {description: "lextreme:subset=online_terms_of_service_unfairness_levels,model=text", priority: 5}
  {description: "lextreme:subset=online_terms_of_service_clause_topics,model=text", priority: 5}
  {description: "lextreme:subset=covid19_emergency_event,model=text", priority: 5}
  {description: "lextreme:subset=multi_eurlex_level_1,model=text", priority: 5}
  {description: "lextreme:subset=multi_eurlex_level_2,model=text", priority: 5}
  {description: "lextreme:subset=multi_eurlex_level_3,model=text", priority: 5}
  {description: "lextreme:subset=greek_legal_ner,model=text", priority: 5}
  {description: "lextreme:subset=legalnero,model=text", priority: 5}
  {description: "lextreme:subset=lener_br,model=text", priority: 5}
  {description: "lextreme:subset=mapa_coarse,model=text", priority: 5}
  {description: "lextreme:subset=mapa_fine,model=text", priority: 5}

  {description: "lex_glue:subset=ecthr_a,model=text", priority: 3}
  {description: "lex_glue:subset=ecthr_b,model=text", priority: 3}
  {description: "lex_glue:subset=scotus,model=text", priority: 3}
  {description: "lex_glue:subset=eurlex,model=text", priority: 3}
  {description: "lex_glue:subset=ledgar,model=text", priority: 3}
  {description: "lex_glue:subset=unfair_tos,model=text", priority: 3}
  {description: "lex_glue:subset=case_hold,model=text", priority: 3}

  {description: "billsum_legal_summarization:model=text", priority: 3},
  {description: "multilexsum_legal_summarization:model=text", priority: 3},
  {description: "eurlexsum_legal_summarization:model=text", priority: 3},

  # MedQA
  {description: "med_qa:model=biomedical", priority: 2}

  # Data processing

  {description: "entity_matching:model=text,dataset=Beer", priority: 2}
  {description: "entity_matching:model=text,dataset=Abt_Buy", priority: 2}
  {description: "entity_matching:model=text,dataset=Dirty_iTunes_Amazon", priority: 2}

  {description: "entity_data_imputation:model=text,dataset=Buy", priority: 2}
  {description: "entity_data_imputation:model=text,dataset=Restaurant", priority: 2}

  # Code
  {description: "code:model=code,dataset=humaneval", priority: 1}
  {description: "code:model=code,dataset=apps,timeout=3", priority: 1}

  {description: "big_bench:model=text,max_train_instances=big_bench_few_shot_setting,task=semantic_parsing_spider,subtask=", priority: 3}


  ##### Harms #####

  ## Copyright

  # Randomly sampled instances from the original BooksCorpus.
  # We expect data here to be less repeated in the pretraining corpus. This approximates the average case.
  {description: "copyright:model=text,datatag=n_books_1000-extractions_per_book_1-prefix_length_125", priority: 1}

  # We expect data here to be repeated more in the pretraining corpus. This approximates the worst case.
  {description: "copyright:model=text,datatag=popular_books-prefix_length_125.json", priority: 1}

  # Large and small codex models.
  {description: "copyright:model=code,datatag=prompt_num_line_1-min_lines_20.json", priority: 2}
  {description: "copyright:model=code,datatag=prompt_num_line_5-min_lines_20.json", priority: 3}
  {description: "copyright:model=code,datatag=prompt_num_line_10-min_lines_20.json", priority: 2}

  ## Disinformation

  {description: "disinformation:model=text,capability=reiteration,topic=climate", priority: 1}
  {description: "disinformation:model=text,capability=reiteration,topic=covid", priority: 1}
  {description: "disinformation:model=text,capability=wedging", priority: 1}

  ## Bias

  {description: "bbq:model=text,subject=all", priority: 2}
  {description: "bbq:model=text,subject=age", priority: 3}
  {description: "bbq:model=text,subject=disability_status", priority: 3}
  {description: "bbq:model=text,subject=gender_identity", priority: 3}
  {description: "bbq:model=text,subject=nationality", priority: 3}
  {description: "bbq:model=text,subject=physical_appearance", priority: 3}
  {description: "bbq:model=text,subject=race_ethnicity", priority: 3}
  {description: "bbq:model=text,subject=race_x_SES", priority: 3}
  {description: "bbq:model=text,subject=race_x_gender", priority: 3}
  {description: "bbq:model=text,subject=religion", priority: 3}
  {description: "bbq:model=text,subject=SES", priority: 3}
  {description: "bbq:model=text,subject=sexual_orientation", priority: 3}

  ## Toxicity

  {description: "real_toxicity_prompts:model=text", priority: 2}

  {description: "bold:model=text,subject=all", priority: 2}
  {description: "bold:model=text,subject=gender", priority: 3}
  {description: "bold:model=text,subject=political_ideology", priority: 3}
  {description: "bold:model=text,subject=profession", priority: 3}
  {description: "bold:model=text,subject=race", priority: 3}
  {description: "bold:model=text,subject=religious_ideology", priority: 3}


  ##### Efficiency #####

  {description: "synthetic_efficiency:model=text,tokenizer=default,num_prompt_tokens=default_sweep,num_output_tokens=default_sweep", priority: 1}
  {description: "synthetic_efficiency:model=code,tokenizer=default,num_prompt_tokens=default_sweep,num_output_tokens=default_sweep", priority: 1}

  ##### Robustness #####

  ## Contrast sets (these are separate runs since we will only consider Instances that have contrast sets
  {description: "boolq:model=text,only_contrast=True,data_augmentation=contrast_sets", priority: 2, groups: ["robustness_contrast_sets"]}
  {description: "imdb:model=text,only_contrast=True,data_augmentation=contrast_sets", priority: 2, groups: ["robustness_contrast_sets"]}

  ##### Instruction Following #####

  {description: "self_instruct:model=instruction_following,num_respondents=1", priority: 1}
  {description: "grammar:path=src/helm/benchmark/scenarios/best_chatgpt_prompts.yaml,tags=,model=instruction_following,num_respondents=1", priority: 1}
  {description: "open_assistant:language=en,model=instruction_following,num_respondents=1", priority: 1}
  {description: "vicuna:model=instruction_following,num_respondents=1", priority: 1}
  {description: "koala:model=instruction_following,num_respondents=1", priority: 1}
  {description: "anthropic_hh_rlhf:subset=hh,model=instruction_following,num_respondents=1", priority: 1}
  {description: "anthropic_hh_rlhf:subset=red_team,model=instruction_following,num_respondents=1", priority: 3}

  ### Simple elementary school level tasks ###

  # Scenario: LM Entry
  {description: "lm_entry:model=text,task=all_words_from_category", priority: 3}
  {description: "lm_entry:model=text,task=any_words_from_category", priority: 3}
  {description: "lm_entry:model=text,task=bigger_number", priority: 3}
  {description: "lm_entry:model=text,task=first_alphabetically", priority: 3}
  {description: "lm_entry:model=text,task=first_letter", priority: 3}
  {description: "lm_entry:model=text,task=first_word", priority: 3}
  {description: "lm_entry:model=text,task=homophones", priority: 3}
  {description: "lm_entry:model=text,task=last_letter", priority: 3}
  {description: "lm_entry:model=text,task=last_word", priority: 3}
  {description: "lm_entry:model=text,task=least_associated_word", priority: 3}
  {description: "lm_entry:model=text,task=less_letters", priority: 3}
  {description: "lm_entry:model=text,task=more_letters", priority: 3}
  {description: "lm_entry:model=text,task=most_associated_word", priority: 3}
  {description: "lm_entry:model=text,task=rhyming_word", priority: 3}
  {description: "lm_entry:model=text,task=smaller_number", priority: 3}
  {description: "lm_entry:model=text,task=word_after", priority: 3}
  {description: "lm_entry:model=text,task=word_before", priority: 3}

]
