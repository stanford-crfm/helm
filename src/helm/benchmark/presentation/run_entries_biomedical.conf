# Biomedical RunSpecs
# helm-run --suite biomed --conf-path src/helm/benchmark/presentation/run_entries_biomedical.conf -m 1000

entries: [
    ######################################################### NLU ######################################################

    {description: "med_mcqa:model=biomedical", priority: 1}

    {description: "med_qa:model=biomedical", priority: 1}
    # Also evaluate MedQA zero-shot
    {description: "med_qa:model=biomedical,max_train_instances=zero", priority: 1}

    {description: "pubmed_qa:model=biomedical", priority: 1}

    # MMLU
    {description: "mmlu:model=biomedical,subject=medical_genetics", priority: 1}
    {description: "mmlu:model=biomedical,subject=professional_medicine", priority: 1}

    # BIG-bench
    {description: "big_bench:model=biomedical,task=cryobiology_spanish,subtask=", priority: 1}
    {description: "big_bench:model=biomedical,task=medical_questions_russian,subtask=", priority: 1}
    {description: "big_bench:model=biomedical,task=suicide_risk,subtask=", priority: 1}


    ######################################################### NLG ######################################################

    {description: "covid_dialog:model=biomedical", priority: 1}

    {description: "me_q_sum:model=biomedical", priority: 1}

    {description: "med_dialog:model=biomedical,subset=healthcaremagic", priority: 1}
    {description: "med_dialog:model=biomedical,subset=icliniq", priority: 1}

    {description: "med_paragraph_simplification:model=biomedical", priority: 1}
]
