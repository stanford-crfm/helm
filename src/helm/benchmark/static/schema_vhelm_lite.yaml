---
############################################################
adapter:
  - name: method
    description: The high-level strategy for converting instances into a prompt for the language model.
    values:
      - name: generation
        description: Given the input, the model generates the output free-form.
      - name: generation_multimodal
        description: Given the multimodal input, the model generates the output free-form.
      - name: multiple_choice_joint
        description: Given the input, the model selects from multiple-choice options (A., B., C., D., E.).
      - name: multiple_choice_joint_multimodal
        description: Given the multimodal input, the model selects from multiple-choice options (A., B., C., D., E.).
  - name: instructions
    description: The description of the task that is included at the very beginning of the prompt.
  - name: global_prefix
    description: The string that is prepended to the prompt.
  - name: global_suffix
    description: The string that is appended to the prompt.
  - name: instance_prefix
    description: The string that is included before each instance (e.g., '\n\n').
  - name: input_prefix
    description: The string that is included before each input (e.g., 'Question:').
  - name: input_suffix
    description: The string that is included after each input (e.g., '\n').
  - name: reference_prefix
    description: The string that is included before each reference (for multiple-choice questions).
  - name: reference_suffix
    description: The string that is included after each reference (for multiple-choice questions).
  - name: output_prefix
    description: The string that is included before the correct answer/predicted output (e.g., 'Answer:').
  - name: output_suffix
    description: The string that is included after the correct answer/predicted output (e.g., '\n').
  - name: substitutions
    description: A list of regular expression substitutions (e.g., replacing '\n' with ';\n') to perform at the very end on the prompt.
  - name: max_train_instances
    description: Maximum number of training instances to include in the prompt (currently by randomly sampling).
  - name: max_eval_instances
    description: Maximum number of instances to evaluate on (over all splits - test, valid, etc.).
  - name: num_outputs
    description: Maximum number of possible outputs to generate by sampling multiple outputs.
  - name: num_train_trials
    description: Number of trials, where in each trial we choose an independent, random set of training instances. Used to compute variance.
  - name: sample_train
    description: If true, randomly sample N training examples; if false, select N consecutive training examples
  - name: model
    description: Name of the language model (<creator_organization>/<model name>) to send requests to.
  - name: model_deployment
    description: Name of the language model deployment (<host_organization>/<model name>) to send requests to.
  - name: temperature
    description: Temperature parameter used in generation.
  - name: max_tokens
    description: Maximum number of tokens to generate.
  - name: stop_sequences
    description: List of sequences, where we stop generation if we encounter any of them.
  - name: random
    description: Random seed (string), which guarantees reproducibility.
  - name: multi_label
    description: If true, for instances with multiple correct reference, the gold answer should be considered to be all of the correct references rather than any of the correct references.

perturbations:
  - name: robustness
    display_name: Robustness
    description: Computes worst case over different robustness perturbations (misspellings, formatting, contrast sets).

############################################################
metrics:
  # Accuracy metrics:
  - name: exact_match
    display_name: Exact match
    short_display_name: EM
    description: Fraction of instances that the predicted output matches a correct reference exactly.
    lower_is_better: false
  - name: quasi_exact_match
    display_name: Quasi-exact match
    short_display_name: EM
    description: Fraction of instances that the predicted output matches a correct reference up to light processing.
    lower_is_better: false
  - name: prefix_exact_match
    display_name: Prefix exact match
    short_display_name: PEM
    description: Fraction of instances that the predicted output matches the prefix of a correct reference exactly.
    lower_is_better: false
  - name: quasi_prefix_exact_match
    # TODO: should call this prefix_quasi_exact_match
    display_name: Prefix quasi-exact match
    short_display_name: PEM
    description: Fraction of instances that the predicted output matches the prefix of a correct reference up to light processing.
    lower_is_better: false

  - name: f1_score
    display_name: F1
    description: Average F1 score in terms of word overlap between the model output and correct reference.
    lower_is_better: false
  - name: cider
    display_name: CIDEr
    description: Evaluates the quality of generated caption by measuring the weighted similarity of n-grams between the captions and a set of human-written reference captions, emphasizing informativeness and consensus.
    lower_is_better: false


############################################################
metric_groups:
  - name: accuracy
    display_name: Accuracy
    metrics:
      - name: ${main_name}
        split: ${main_split}

############################################################
run_groups:
  - name: core_scenarios
    display_name: Core scenarios
    description: The scenarios where we evaluate all the models.
    category: All scenarios
    subgroups:
      - viz_wiz
      - vqa
      - mmmu

  - name: viz_wiz
    display_name: VizWiz
    description: A benchmark for visual question answering with images and questions created by visually impaired people [(Gurari et al., 2018)](https://arxiv.org/abs/1802.08218).
    metric_groups:
      - accuracy
    environment:
      main_name: quasi_exact_match
      main_split: valid
    taxonomy:
      task: multimodal short answer question answering
      what: Real-world images
      who: Visually impaired people
      when: "2018"
      language: English

  - name: vqa
    display_name: VQAv2
    description: Open-ended questions about real-world images [(Goyal et al., 2017)](https://arxiv.org/abs/1612.00837).
    metric_groups:
      - accuracy
    environment:
      main_name: quasi_exact_match
      main_split: valid
    taxonomy:
      task: multimodal short answer question answering
      what: Real-world images
      who: Human experts
      when: "2017"
      language: English

  - name: mmmu
    display_name: MMMU
    description: A benchmark designed to evaluate multimodal models on massive multi-discipline tasks demanding college-level subject knowledge and deliberate reasoning [(Yue et al., 2023)](https://arxiv.org/abs/2311.16502).
    metric_groups:
      - accuracy
    environment:
      main_name: exact_match
      main_split: valid
    taxonomy:
      task: multimodal multiple-choice question answering
      what: Art & Design, Business, Science, Health & Medicine, Humanities & Social Science, and Tech & Engineering
      who: Human experts
      when: "2023"
      language: English
