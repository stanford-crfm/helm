---
############################################################
models:
  # Text-to-Image
  - name: AlephAlpha/m-vader
    display_name: MultiFusion
    description: MultiFusion is similar to Stable Diffusion, but it supports multimodal inputs and the text encoder is a Luminous model ([paper](https://arxiv.org/abs/2305.15296)).
    creator_organization: Aleph Alpha
    access: open
  - name: adobe/giga-gan
    display_name: GigaGAN (1B)
    description: GigaGAN (1B parameters)
    creator_organization: Adobe
    access: limited
    todo: true
  - name: adobe/firefly
    display_name: Firefly
    description: Adobe Firefly was trained on the Adobe Stock dataset, along with openly licensed work and public domain content where copyright has expired.
    creator_organization: Adobe
    access: limited
    todo: true
  - name: openai/dalle-2
    display_name: DALL-E 2 (3.5B)
    description: DALL-E 2 (3.5B parameters) is a model that can create realistic images and art from a description in natural language.
    creator_organization: OpenAI
    access: limited
  - name: lexica/search-stable-diffusion-1.5
    display_name: Lexica Search with Stable Diffusion v1.5
    description: Retrieves Stable Diffusion v1.5 images Lexica users generated.
    creator_organization: Lexica
    access: limited
  - name: DeepFloyd/IF-I-M-v1.0
    display_name: DeepFloyd IF Medium
    description: DeepFloyd IF is a novel state-of-the-art open-source text-to-image model with a high degree of photorealism and language understanding.
    creator_organization: DeepFloyd
    access: open
    todo: true
  - name: DeepFloyd/IF-I-L-v1.0
    display_name: DeepFloyd IF Large
    description: DeepFloyd IF is a novel state-of-the-art open-source text-to-image model with a high degree of photorealism and language understanding.
    creator_organization: DeepFloyd
    access: open
    todo: true
  - name: DeepFloyd/IF-I-XL-v1.0
    display_name: DeepFloyd IF X-Large
    description: DeepFloyd IF is a novel state-of-the-art open-source text-to-image model with a high degree of photorealism and language understanding.
    creator_organization: DeepFloyd
    access: open
    todo: true
  - name: kakaobrain/mindall-e
    display_name: minDALL-E (1.3B)
    description: minDALL-E, named after minGPT, is a 1.3B text-to-image generation model trained on 14 million image-text pairs for non-commercial purposes.
    creator_organization: Kakao Brain
    access: open
  - name: craiyon/dalle-mini
    display_name: DALL-E mini (0.4B)
    description: DALL-E mini (0.4B parameters) is an open-source text-to-image model that attempt to reproduce OpenAI DALL-E 1.
    creator_organization: Craiyon
    access: open
  - name: craiyon/dalle-mega
    display_name: DALL-E mega (2.6B)
    description: DALL-E mini (2.6B parameters) is an open-source text-to-image model that attempt to reproduce OpenAI DALL-E 1.
    creator_organization: Craiyon
    access: open
  - name: thudm/cogview2
    display_name: CogView2
    description: CogView2 is a hierarchical transformer (6B-9B-9B parameters) for text-to-image generation in general domain.
    creator_organization: Craiyon
    access: open
  - name: huggingface/dreamlike-photoreal-v2-0
    display_name: Dreamlike Photoreal v2.0
    description: Dreamlike Photoreal v2.0 is a photorealistic model based on Stable Diffusion v1.5.
    creator_organization: dreamlike.art
    access: open
  - name: huggingface/dreamlike-diffusion-v1-0
    display_name: Dreamlike Diffusion v1.0
    description: Dreamlike Diffusion v1.0 is Stable Diffusion v1.5 fine tuned on high quality art.
    creator_organization: dreamlike.art
    access: open
  - name: huggingface/openjourney-v1-0
    display_name: Openjourney v1.0
    description: Openjourney is an open source Stable Diffusion fine tuned model on Midjourney images
    creator_organization: PromptHero
    access: open
  - name: huggingface/openjourney-v2-0
    display_name: Openjourney v2.0
    description: Openjourney v2 is an open source Stable Diffusion fine tuned model on +60k Midjourney images
    creator_organization: PromptHero
    access: open
  - name: huggingface/redshift-diffusion
    display_name: Redshift Diffusion
    description: Redshift Diffusion is an open source Stable Diffusion fine tuned on high resolution 3D artworks.
    creator_organization: nitrosocke
    access: open
  - name: huggingface/promptist-stable-diffusion-v1-4
    display_name: Promptist + Stable Diffusion v1.4
    description: Promptist optimizes user input into model-preferred prompts for Stable Diffusion v1.4.
    creator_organization: Microsoft
    access: open
  - name: huggingface/stable-diffusion-v1-4
    display_name: Stable Diffusion v1.4
    description: Stable Diffusion v1.4 is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input.
    creator_organization: Ludwig Maximilian University of Munich CompVis
    access: open
  - name: huggingface/stable-diffusion-v1-5
    display_name: Stable Diffusion v1.5
    description: The Stable-Diffusion-v1-5 checkpoint was initialized with the weights of the Stable-Diffusion-v1-2 checkpoint and subsequently fine-tuned on 595k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling.
    creator_organization: Runway
    access: open
  - name: huggingface/stable-diffusion-v2-base
    display_name: Stable Diffusion v2 base
    description: The model is trained from scratch 550k steps at resolution 256x256 on a subset of LAION-5B filtered for explicit pornographic material, using the LAION-NSFW classifier with punsafe=0.1 and an aesthetic score >= 4.5. Then it is further trained for 850k steps at resolution 512x512 on the same dataset on images with resolution >= 512x512.
    creator_organization: Stability AI
    access: open
  - name: huggingface/stable-diffusion-v2-1-base
    display_name: Stable Diffusion v2.1 base
    description: This stable-diffusion-2-1-base model fine-tunes stable-diffusion-2-base with 220k extra steps taken, with punsafe=0.98 on the same dataset.
    creator_organization: Stability AI
    access: open
  - name: huggingface/stable-diffusion-safe-weak
    display_name: Safe Stable Diffusion weak
    description: Safe Stable Diffusion is an extension to the Stable Diffusion that drastically reduces inappropriate content.
    creator_organization: TU Darmstadt
    access: open
  - name: huggingface/stable-diffusion-safe-medium
    display_name: Safe Stable Diffusion medium
    description: Safe Stable Diffusion is an extension to the Stable Diffusion that drastically reduces inappropriate content.
    creator_organization: TU Darmstadt
    access: open
  - name: huggingface/stable-diffusion-safe-strong
    display_name: Safe Stable Diffusion strong
    description: Safe Stable Diffusion is an extension to the Stable Diffusion that drastically reduces inappropriate content.
    creator_organization: TU Darmstadt
    access: open
  - name: huggingface/stable-diffusion-safe-max
    display_name: Safe Stable Diffusion max
    description: Safe Stable Diffusion is an extension to the Stable Diffusion that drastically reduces inappropriate content.
    creator_organization: TU Darmstadt
    access: open
  - name: huggingface/vintedois-diffusion-v0-1
    display_name: Vintedois (22h) Diffusion model v0.1
    description: Vintedois (22h) Diffusion model v0.1 is Stable Diffusion v1.5 that was finetuned on a large amount of high quality images with simple prompts to generate beautiful images without a lot of prompt engineering.
    creator_organization: 22 Hours
    access: open

############################################################
adapter:
  - name: method
    description: The high-level strategy for converting instances into a prompt for the language model.
    values:
      - name: generation
        description: Given the input, the model generates the output free-form.
      - name: multiple_choice_joint
        description: Given the input, the model selects from multiple-choice options (A., B., C., D., E.).
      - name: multiple_choice_separate_original
        description: For each answer choice, the model assigns the input and answer choice a probability, returning the answer with maximum probability.
      - name: multiple_choice_separate_calibrated
        description: For each answer choice, the model assigns the input and answer choice a probability, returning the answer with maximum probability when calibrated by answer choice probability.
      - name: language_modeling
        description: Given the input, the model assigns the sequence a probability.
  - name: instructions
    description: The description of the task that is included at the very beginning of the prompt.
  - name: global_prefix
    description: The string that is prepended to the prompt.
  - name: instance_prefix
    description: The string that is included before each instance (e.g., '\n\n').
  - name: input_prefix
    description: The string that is included before each input (e.g., 'Question:').
  - name: input_suffix
    description: The string that is included after each input (e.g., '\n').
  - name: reference_prefix
    description: The string that is included before each reference (for multiple-choice questions).
  - name: reference_suffix
    description: The string that is included after each reference (for multiple-choice questions).
  - name: output_prefix
    description: The string that is included before the correct answer/predicted output (e.g., 'Answer:').
  - name: output_suffix
    description: The string that is included after the correct answer/predicted output (e.g., '\n').
  - name: substitutions
    description: A list of regular expression substitutions (e.g., replacing '\n' with ';\n') to perform at the very end on the prompt.
  - name: max_train_instances
    description: Maximum number of training instances to include in the prompt (currently by randomly sampling).
  - name: max_eval_instances
    description: Maximum number of instances to evaluate on (over all splits - test, valid, etc.).
  - name: num_outputs
    description: Maximum number of possible outputs to generate by sampling multiple outputs.
  - name: num_train_trials
    description: Number of trials, where in each trial we choose an independent, random set of training instances. Used to compute variance.
  - name: model
    description: Name of the language model (<organization>/<model name>) to send requests to.
  - name: temperature
    description: Temperature parameter used in generation.
  - name: max_tokens
    description: Maximum number of tokens to generate.
  - name: stop_sequences
    description: List of sequences, where we stop generation if we encounter any of them.
  - name: random
    description: Random seed (string), which guarantees reproducibility.

############################################################
metrics:
  # Infrastructure metrics:
  - name: num_perplexity_tokens
    display_name: '# tokens'
    description: Average number of tokens in the predicted output (for language modeling, the input too).
  - name: num_bytes
    display_name: '# bytes'
    description: Average number of bytes in the predicted output (for language modeling, the input too).

  - name: num_references
    display_name: '# ref'
    description: Number of references.
  - name: num_train_trials
    display_name: '# trials'
    description: Number of trials, where in each trial we choose an independent, random set of training instances.
  - name: estimated_num_tokens_cost
    display_name: 'cost'
    description: An estimate of the number of tokens (including prompt and output completions) needed to perform the request.
  - name: num_prompt_tokens
    display_name: '# prompt tokens'
    description: Number of tokens in the prompt.
  - name: num_prompt_characters
    display_name: '# prompt chars'
    description: Number of characters in the prompt.
  - name: num_completion_tokens
    display_name: '# completion tokens'
    description: Actual number of completion tokens (over all completions).
  - name: num_output_tokens
    display_name: '# output tokens'
    description: Actual number of output tokens.
  - name: max_num_output_tokens
    display_name: 'Max output tokens'
    description: Maximum number of output tokens (overestimate since we might stop earlier due to stop sequences).
  - name: num_requests
    display_name: '# requests'
    description: Number of distinct API requests.
  - name: num_instances
    display_name: '# eval'
    description: Number of evaluation instances.
  - name: num_train_instances
    display_name: '# train'
    description: Number of training instances (e.g., in-context examples).
  - name: prompt_truncated
    display_name: truncated
    description: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).
  - name: finish_reason_length
    display_name: finish b/c length
    description: Fraction of instances where the the output was terminated because of the max tokens limit.
  - name: finish_reason_stop
    display_name: finish b/c stop
    description: Fraction of instances where the the output was terminated because of the stop sequences.
  - name: finish_reason_endoftext
    display_name: finish b/c endoftext
    description: Fraction of instances where the the output was terminated because the end of text token was generated.
  - name: finish_reason_unknown
    display_name: finish b/c unknown
    description: Fraction of instances where the the output was terminated for unknown reasons.
  - name: num_completions
    display_name: '# completions'
    description: Number of completions.
  - name: predicted_index
    display_name: Predicted index
    description: Integer index of the reference (0, 1, ...) that was predicted by the model (for multiple-choice).

  # Efficiency metrics:
  - name: training_co2_cost
    display_name: Estimated training emissions (kg CO2)
    short_display_name: Training emissions (kg CO2)
    lower_is_better: true
    description: Estimate of the CO2 emissions from training the model.
  - name: training_energy_cost
    display_name: Estimated training energy cost (MWh)
    short_display_name: Training energy (MWh)
    lower_is_better: true
    description: Estimate of the amount of energy used to train the model.
  - name: inference_runtime
    display_name: Observed inference runtime (s)
    short_display_name: Observed inference time (s)
    lower_is_better: true
    description: Average observed time to process a request to the model (via an API, and thus depends on particular deployment).
  - name: inference_idealized_runtime
    display_name: Idealized inference runtime (s)
    short_display_name: Idealized inference time (s)
    lower_is_better: true
    description: Average time to process a request to the model based solely on the model architecture (using Megatron-LM).
  - name: inference_denoised_runtime
    display_name: Denoised inference runtime (s)
    short_display_name: Denoised inference time (s)
    lower_is_better: true
    description: Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.
  - name: batch_size
    display_name: Batch size
    description: For batch jobs, how many requests are in a batch.


  ##  HEIM metrics

  # Fidelity
  - name: fid
    display_name: FID
    short_display_name: FID
    description: FrÃ©chet Inception Distance (FID) is a benchmark metric used for evaluating the quality of images generated by models.
    lower_is_better: true
  - name: inception_score
    display_name: Inception Score (IS)
    short_display_name: Inception Score
    description: Inception score (IS) is a benchmark metric used for evaluating the quality of image-based generative models.
    lower_is_better: false
  - name: kernel_inception_distance
    display_name: Kernel Inception Distance (KID)
    short_display_name: Kernel Inception Distance
    description: TODO
    lower_is_better: true
  - name: expected_lpips_score
    display_name: Expected Learned Perceptual Image Patch Similarity (LPIPS) score
    short_display_name: Expected LPIPS score
    description: TODO
    lower_is_better: true
  - name: expected_multi_scale_ssim_score
    display_name: Expected Multi-scale Structural Similarity Index Measure (SSIM)
    short_display_name: Expected Multi-Scale SSIM
    description: TODO
    lower_is_better: false
  - name: expected_psnr_score
    display_name: Expected Peak Signal-to-Noise Ratio (PSNR)
    short_display_name: Expected PSNR
    description: TODO
    lower_is_better: false
  - name: expected_uiqi_score
    display_name: Expected Universal Image Quality Index (UIQI)
    short_display_name: Expected UIQI
    description: TODO
    lower_is_better: false

  # Bias
  - name: gender_imbalance
    display_name: Gender imbalance
    short_display_name: Gender imbalance
    description: Assesses the presence of binary gender bias within a set of images.
    lower_is_better: True
  - name: skin_tone_imbalance
    display_name: Skin tone imbalance
    short_display_name: Skin tone imbalance
    description: This metric assesses the presence of skin tone bias within a set of images.
    lower_is_better: True

  # CLIP score
  - name: expected_clip_score
    display_name: Expected CLIP score
    short_display_name: Expected CLIP score
    description: CLIPscore measures how well an image is aligned with a corresponding natural language description, using the pre-trained CLIP model.
    lower_is_better: false
  - name: max_clip_score
    display_name: Maximum CLIP score
    short_display_name: Max CLIP score
    description: CLIPscore measures how well an image is aligned with a corresponding natural language description, using the pre-trained CLIP model.
    lower_is_better: false

  # Detection
  - name: detection_correct_frac
    display_name: Detection correct fraction
    short_display_name: Detection correct frac
    description: Fraction of correct images according to the ViTDet object detector with ViT-B backbone and detectron2 library to automatically detect objects specified in the prompts.
    lower_is_better: false

  # Aesthetics
  - name: expected_aesthetics_score
    display_name: Expected aesthetics score
    short_display_name: Expected aesthetics score
    description: Following LAION-Aesthetics for determining the aesthetic score of a generated image.
    lower_is_better: false
  - name: max_aesthetics_score
    display_name: Maximum aesthetics score
    short_display_name: Max aesthetics score
    description: Following LAION-Aesthetics for determining the aesthetic score of a generated image.
    lower_is_better: false
  - name: aesthetics_human
    display_name: Aesthetics (human)
    short_display_name: Aesthetics (human)
    description: How aesthetically pleasing is the image according to human evaluators.
    lower_is_better: false

  # Image quality
  - name: image_text_alignment_human
    display_name: Image text alignment (human)
    short_display_name: Image text alignment (human)
    description: How well does the image match the description according to human evaluators.
    lower_is_better: false
  - name: clear_subject_human
    display_name: Clear subject (human)
    short_display_name: Clear subject (human)
    description: Is it clear who the subject(s) of the image is according to human evaluators.
    lower_is_better: false

  # Originality
  - name: originality_human
    display_name: Originality (human)
    short_display_name: Originality (human)
    description: How original is the image, given it was created with the description according to human evaluators.
    lower_is_better: false
  - name: copyright_human
    display_name: Copyright (human)
    short_display_name: Copyright (human)
    description: TODO
    lower_is_better: true

  # NSFW
  - name: toxic_prompt_perspective_api
    display_name: Toxic prompt (Perspective API)
    short_display_name: Toxic prompt (Perspective API)
    description: TODO
    lower_is_better: true
  - name: toxic_prompt_openai
    display_name: Toxic prompt (OpenAI)
    short_display_name: Toxic prompt (OpenAI)
    description: TODO
    lower_is_better: true
  - name: expected_max_nsfw_score
    display_name: Expected maximum NSFW score
    short_display_name: Expected max NSFW score
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: expected_max_nsfw_score_given_toxic_prompt=True
    display_name: Expected maximum NSFW score given toxic prompt
    short_display_name: Expected max NSFW score given toxic prompt
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: expected_max_nsfw_score_given_toxic_prompt=False
    display_name: Expected maximum NSFW score given non-toxic prompt
    short_display_name: Expected max NSFW score given non-toxic prompt
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: fractal_dimension
    display_name: Expected fractal dimension
    short_display_name: Expected fractal dimension
    description: Fractal coefficient is a measure of the fractal patterns in an image
    lower_is_better: false
  - name: max_nsfw_probability
    display_name: Expected maximum NSFW probability
    short_display_name: Expected max NSFW probability
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: max_nsfw_probability_given_toxic_prompt=True
    display_name: Expected maximum NSFW probability given toxic prompt
    short_display_name: Expected max NSFW probability given toxic prompt
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: max_nsfw_probability_given_toxic_prompt=False
    display_name: Expected maximum NSFW probability given non-toxic prompt
    short_display_name: Expected max NSFW probability given non-toxic prompt
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: nsfw_frac
    display_name: NSFW frac
    short_display_name: NSFW frac
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: nsfw_frac_given_toxic_prompt=True
    display_name: NSFW frac given toxic prompt
    short_display_name: NSFW frac given toxic prompt
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: nsfw_frac_given_toxic_prompt=False
    display_name: NSFW frac given non-toxic prompt
    short_display_name: NSFW frac given non-toxic prompt
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: nudity_frac
    display_name: Nudity frac
    short_display_name: Nudity frac
    description: Pre-trained NudeNet to determine whether an image contains nudity.
    lower_is_better: true
  - name: blacked_out_frac
    display_name: Blacked out frac
    short_display_name: Blacked out frac
    description: This metric represents whether the image has been blacked out.
    lower_is_better: true
  - name: blacked_out_frac_given_toxic_prompt=True
    display_name: Blacked out frac given toxic prompt
    short_display_name: Blacked out frac given toxic prompt
    description: This metric represents whether the image has been blacked out.
    lower_is_better: true
  - name: blacked_out_frac_given_toxic_prompt=False
    display_name: Blacked out frac given non-toxic prompt
    short_display_name: Blacked out frac given non-toxic prompt
    description: This metric represents whether the image has been blacked out.
    lower_is_better: true

  # Watermark
  - name: watermark_frac
    display_name: Watermark frac
    short_display_name: Watermark frac
    description: Watermark detector from LAION to determine whether an image contains watermarks.
    lower_is_better: true
  - name: expected_max_watermark_prob
    display_name: Expected maximum watermark prob
    short_display_name: Expected max watermark prob
    description: Watermark detector from LAION to determine whether an image contains watermarks.
    lower_is_better: true

  # Photorealism
  - name: photorealism_generated_human
    display_name: Photorealism w/ generated images (human)
    short_display_name: Photorealism - generated (human)
    description: Determine if the following image is AI-generated or real according to human raters.
    lower_is_better: false
  - name: photorealism_real_human
    display_name: Photorealism w/ real images (human)
    short_display_name: Photorealism - real (human)
    description: Determine if the following image is AI-generated or real according to human raters.
    lower_is_better: false

  # Efficiency for image generation
  - name: denoised_runtime
    display_name: Denoised runtime (in seconds)
    short_display_name: Denoised runtime (s)
    description: Denoised runtime
    lower_is_better: true
  - name: prompt_length
    display_name: Prompt length (number of characters)
    short_display_name: Prompt length (characters)
    description: TODO
    lower_is_better: false
  - name: inference_runtime
    display_name: Inference runtime (in seconds)
    short_display_name: Inference runtime (s)
    description: TODO
    lower_is_better: true
  - name: num_generated_images
    display_name: Number of generated images
    short_display_name: Number of generated images
    description: TODO
    lower_is_better: false

############################################################
perturbations:
  - name: robustness
    display_name: Robustness
    description: Computes worst case over different robustness perturbations (misspellings, formatting, contrast sets).
  - name: fairness
    display_name: Fairness
    description: Computes worst case over different fairness perturbations (changing dialect, race of names, gender).
  - name: typos
    display_name: Typos
    description: >
      Randomly adds typos to each token in the input with probability 0.05 and computes the per-instance worst-case
      performance between perturbed and unperturbed versions.
  - name: synonym
    display_name: Synonyms
    description: >
      Randomly substitutes words in the input with WordNet synonyms with probability 0.5 and computes the per-instance
      worst-case performance between perturbed and unperturbed versions.
  - name: dialect
    display_name: SAE -> AAE
    short_display_name: Dialect
    description: >
      Deterministically substitutes SAE words in input with AAE counterparts using validated dictionary of [Ziems et al. (2022)](https://aclanthology.org/2022.acl-long.258/) and computes the per-instance worst-case performance between perturbed and unperturbed versions.
  - name: race
    display_name: First names by race (White -> Black)
    short_display_name: Race
    description: >
      Deterministically substitutes White first names with Black first names sampled from the lists of [Caliskan et al. (2017)](https://www.science.org/doi/10.1126/science.aal4230) and computes the per-instance worst-case performance between perturbed and unperturbed versions.
  - name: gender
    display_name: Pronouns by gender (Male -> Female)
    short_display_name: Gender
    description: >
      Deterministically substitutes male pronouns with female pronouns and computes the per-instance worst-case
      performance between perturbed and unperturbed versions.
  - name: translate
    display_name: Translate
    short_display_name: Translate
    description: >
      Translate text to other languages.

############################################################
metric_groups:

  - name: efficiency
    display_name: Efficiency
    metrics:
    - name: inference_denoised_runtime
      split: ${main_split}

  - name: efficiency_detailed
    display_name: Efficiency
    description: The efficiency of the model across both training and inference.
    metrics:
      - name: inference_runtime
        split: ${main_split}
      - name: inference_idealized_runtime
        split: ${main_split}
      - name: inference_denoised_runtime
        split: ${main_split}
      - name: training_co2_cost
        split: ${main_split}
      - name: training_energy_cost
        split: ${main_split}

  - name: general_information
    display_name: General information
    metrics:
    - name: num_instances
      split: ${main_split}
    - name: prompt_truncated
      split: ${main_split}
    - name: num_prompt_tokens
      split: ${main_split}

  - name: vhelm_inception
    display_name: HEIM inception metrics
    metrics:
      - name: fid
        split: __all__
      - name: inception_score
        split: __all__
      - name: kernel_inception_distance
        split: __all__

  - name: vhelm_fidelity
    display_name: HEIM Image fidelity metrics
    metrics:
      - name: expected_lpips_score
        split: ${main_split}
      - name: expected_multi_scale_ssim_score
        split: ${main_split}
      - name: expected_psnr_score
        split: ${main_split}
      - name: expected_uiqi_score
        split: ${main_split}

  - name: vhelm_gender
    display_name: HEIM gender metrics
    metrics:
      - name: gender_imbalance
        split: ${main_split}

  - name: vhelm_skin_tone
    display_name: HEIM skin tone metrics
    metrics:
      - name: skin_tone_imbalance
        split: ${main_split}



  # HEIM metrics grouped by aspect

    # HEIM metrics grouped by aspect
  # CLIP score
  - name: vhelm_alignment_human_metrics
    display_name: Image-text Alignment - Human Evaluation
    metrics:
      - name: image_text_alignment_human
        split: __all__

  - name: vhelm_alignment_clip_metrics
    display_name: Image-text Alignment - CLIP Score
    metrics:
      - name: expected_clip_score
        split: ${main_split}
      - name: max_clip_score
        split: ${main_split}

  - name: vhelm_quality_human_metrics
    display_name: Quality - Human Evaluation
    metrics:
      - name: photorealism_real_human
        split: __all__
      - name: photorealism_generated_human
        split: __all__

  - name: vhelm_quality_fid_metrics
    display_name: Quality - FID
    metrics:
      - name: fid
        split: __all__

  - name: vhelm_quality_inception_metrics
    display_name: Quality - Inception
    metrics:
      - name: inception_score
        split: __all__
      - name: kernel_inception_distance
        split: __all__

  - name: vhelm_quality_automated_metrics
    display_name: Quality - Other Automated Metrics
    metrics:
      - name: expected_lpips_score
        split: ${main_split}
      - name: expected_multi_scale_ssim_score
        split: ${main_split}
      - name: expected_psnr_score
        split: ${main_split}
      - name: expected_uiqi_score
        split: ${main_split}

  - name: vhelm_aesthetics_human_metrics
    display_name: Aesthetics - Human Evaluation
    metrics:
      - name: clear_subject_human
        split: __all__
      - name: aesthetics_human
        split: __all__

  - name: vhelm_aesthetics_automated_metrics
    display_name: Aesthetics - Automated Metrics
    metrics:
      - name: expected_aesthetics_score
        split: ${main_split}
      - name: max_aesthetics_score
        split: ${main_split}
      - name: fractal_dimension
        split: ${main_split}

  - name: vhelm_originality_human_metrics
    display_name: Originality - Human Evaluation
    metrics:
      - name: originality_human
        split: __all__

  - name: vhelm_originality_watermark_metrics
    display_name: Originality - Watermark
    metrics:
      - name: watermark_frac
        split: ${main_split}


  - name: vhelm_reasoning_metrics
    display_name: Reasoning
    metrics:
      - name: detection_correct_frac
        split: ${main_split}

  - name: vhelm_bias_metrics
    display_name: Bias
    metrics:
      - name: gender_imbalance
        split: ${main_split}
      - name: skin_tone_imbalance
        split: ${main_split}

  - name: vhelm_toxicity_metrics
    display_name: Toxicity (NSFW)
    metrics:
      - name: nsfw_frac_given_toxic_prompt=False
        split: ${main_split}

  - name: vhelm_toxicity_black_metrics
    display_name: Toxicity (blacked out images)
    metrics:
      - name: blacked_out_frac
        split: ${main_split}

  - name: vhelm_toxicity_nudity_metrics
    display_name: Toxicity (nudity)
    metrics:
      - name: nudity_frac
        split: ${main_split}

  - name: vhelm_fairness_metrics
    display_name: Fairness
    metrics:
      - name: expected_clip_score
        split: __all__
        perturbation_name: fairness
      - name: image_text_alignment_human
        split: __all__
        perturbation_name: fairness

  - name: vhelm_robustness_metrics
    display_name: Robustness
    metrics:
      # TOOD: ugh
      - name: expected_clip_score
        split: __all__
        perturbation_name: robustness

  - name: vhelm_multilinguality_metrics
    display_name: Multilinguality
    metrics:
      - name: expected_clip_score_multilingual
        split: ${main_split}
      - name: max_clip_score_multilingual
        split: ${main_split}

  - name: vhelm_efficiency_metrics
    display_name: Efficiency
    metrics:
      # TOOD: ugh
      - name: denoised_runtime
        split: __all__

  - name: vhelm_photorealism
    display_name: HEIM photorealism metrics
    metrics:
      - name: photorealism_generated_human
        split: __all__
      - name: photorealism_real_human
        split: __all__


############################################################
run_groups:
## Top-level
  - name: core_scenarios
    display_name: All scenarios
    description: All scenarios
    # TODO: Could category just be supergroup everywhere?
    category: All scenarios
    subgroups:
      - mscoco_base
      - mscoco_fid
      - mscoco_efficiency
      - mscoco_gender
      - mscoco_dialect
      - mscoco_robustness
      - mscoco_chinese
      - mscoco_hindi
      - mscoco_spanish
      - mscoco_art_styles
      - cub200
      - draw_bench_image_quality
      - parti_prompts_image_quality
      - daily_dalle
      - landing_page
      - logos
      - magazine_cover
      - common_syntactic_processes
      - draw_bench_reasoning
      - parti_prompts_reasoning
      - relational_understanding
      - detection
      - winoground
      - parti_prompts_knowledge
      - draw_bench_knowledge
      - time_most_significant_historical_figures
      - demographic_stereotypes
      - mental_disorders
      - i2p

  # HEIM groups  
  - name: vhelm_alignment_scenarios
    display_name: Alignment
    description: Is the image semantically correct given the text (image-text alignment)
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_base
      - cub200
      - draw_bench_image_quality
      - draw_bench_reasoning
      - draw_bench_knowledge
      - parti_prompts_image_quality
      - parti_prompts_reasoning
      - parti_prompts_knowledge

  - name: vhelm_quality_scenarios
    display_name: Quality
    description: Do the generated images look like real images/photos
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_base
      # Not in paper but should be?
      - draw_bench_image_quality
      - parti_prompts_image_quality

  - name: vhelm_aesthetics_scenarios
    display_name: Aesthetics
    description: Is the image aesthetically pleasing
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_base
      - mscoco_art_styles
      - daily_dalle
      - logos
      - landing_page
      - magazine_cover

  - name: vhelm_originality_scenarios
    display_name: Originality
    description: Does the model generate creative images and prevent copyright infringement
    category: Scenarios for specific aspects
    subgroups:
      - daily_dalle
      - logos
      - landing_page
      - magazine_cover

  - name: vhelm_reasoning_scenarios
    display_name: Reasoning
    description: Does the model understand objects, counts, and spatial relations (compositionality)
    category: Scenarios for specific aspects
    subgroups:
      - common_syntactic_processes
      - draw_bench_reasoning
      - parti_prompts_reasoning
      - relational_understanding
      - detection
      - winoground

  - name: vhelm_knowledge_scenarios
    display_name: Knowledge
    description: Does the model have knowledge about the world or domains
    category: Scenarios for specific aspects
    subgroups:
      - time_most_significant_historical_figures
      - draw_bench_knowledge
      - parti_prompts_knowledge

  - name: vhelm_bias_scenarios
    display_name: Bias
    description: Are the generated images biased in demographic representation (e.g., gender, skin tone)
    category: Scenarios for specific aspects
    subgroups:
      - demographic_stereotypes
      - mental_disorders

  - name: vhelm_toxicity_scenarios
    display_name: Toxicity
    description: Does the model generate toxic or inappropriate images (e.g., violence, sexual, illegal content)
    category: Scenarios for specific aspects
    subgroups:
      - i2p

  - name: vhelm_fairness_gender_scenarios
    display_name: Fairness - gender
    description: Does the model exhibit performance disparities across social groups. The gender perturbation maps male gender terms to female gender terms (e.g., son to daughter and father to mother).
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_gender

  - name: vhelm_fairness_dialect_scenarios
    display_name: Fairness - dialect (AAVE)
    description: Does the model exhibit performance disparities across social groups. The African American Vernacular English (AAVE) dialect perturbation converts each word to the corresponding word in AAVE if one exists.
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_dialect

  - name: vhelm_robustness_scenarios
    display_name: Robustness
    description: Is the model robust to invariant input perturbations
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_robustness

  - name: vhelm_multilinguality_chinese_scenarios
    display_name: Multilinguality (Chinese)
    description: Does the model support non-English languages.
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_chinese

  - name: vhelm_multilinguality_hindi_scenarios
    display_name: Multilinguality (Hindi)
    description: Does the model support non-English languages.
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_hindi

  - name: vhelm_multilinguality_spanish_scenarios
    display_name: Multilinguality (Spanish)
    description: Does the model support non-English languages.
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_spanish

  - name: vhelm_efficiency_scenarios
    display_name: Efficiency
    description: How fast is inference for the model
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_efficiency

  - name: vhelm_art_styles_scenarios
    display_name: Art styles
    description: To test the ability of these models to generate images in specific art styles.
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_art_styles

### Scenarios (the actual scenarios)

  ## HEIM scenarios
  - name: mscoco
    display_name: MS-COCO (all)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)).
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_quality_human_metrics
      - vhelm_quality_automated_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - vhelm_multilinguality_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  # TODO: Merge mscoco_fid with mscoco
  - name: mscoco_fid
    display_name: MS-COCO Fidelity
    description: Fidelity for MS-COCO
    metric_groups:
      - vhelm_quality_fid_metrics
      - vhelm_quality_inception_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  # TODO: Merge mscoco_efficiency with mscoco
  - name: mscoco_efficiency
    display_name: MS-COCO Efficiency
    description: Efficiency for MS-COCO
    metric_groups:
      - vhelm_efficiency_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Efficiency
  - name: mscoco_base
    display_name: MS-COCO (base)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)).
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_quality_human_metrics
      - vhelm_quality_automated_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - vhelm_multilinguality_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_gender
    display_name: MS-COCO (fairness - gender)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)).
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_quality_human_metrics
      - vhelm_quality_automated_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - vhelm_multilinguality_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_dialect
    display_name: MS-COCO (fairness - AAVE dialect)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)).
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_quality_human_metrics
      - vhelm_quality_automated_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - vhelm_multilinguality_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_robustness
    display_name: MS-COCO (robustness)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)).
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_quality_human_metrics
      - vhelm_quality_automated_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - vhelm_multilinguality_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_chinese
    display_name: MS-COCO (Chinese)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)).
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_quality_human_metrics
      - vhelm_quality_automated_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - vhelm_multilinguality_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_hindi
    display_name: MS-COCO (Hindi)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)).
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_quality_human_metrics
      - vhelm_quality_automated_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - vhelm_multilinguality_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_spanish
    display_name: MS-COCO (Spanish)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)).
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_quality_human_metrics
      - vhelm_quality_automated_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - vhelm_multilinguality_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_art_styles
    display_name: MS-COCO (Art styles)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)).
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_quality_human_metrics
      - vhelm_quality_automated_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - vhelm_multilinguality_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: cub200
    display_name: Caltech-UCSD Birds-200-2011
    description: Caltech-UCSD Birds-200-2011 is a challenging dataset of 200 bird species with 10 captions for each bird ([paper](https://authors.library.caltech.edu/27452/1/CUB_200_2011.pdf), [paper](https://arxiv.org/abs/1711.10485)).
    metric_groups:
      - vhelm_alignment_clip_metrics
      - vhelm_quality_fid_metrics
      - vhelm_quality_automated_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Image quality
  - name: draw_bench_image_quality
    display_name: DrawBench (image quality categories)
    description: A comprehensive and challenging set of prompts that support the evaluation and comparison of text-to-image models.
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Image quality
  - name: parti_prompts_image_quality
    display_name: PartiPrompts (image quality categories)
    description: PartiPrompts (P2) is a set of 1600 diverse English prompts that allow us to more comprehensively evaluate and test the limits of text-to-image synthesis models.
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Image quality
  - name: daily_dalle
    display_name: dailydall.e
    description: DALL-E 2 prompts from [Chad Nelson's Instagram](https://www.instagram.com/dailydall.e/)
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_human_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Originality
  - name: landing_page
    display_name: Landing Page
    description: Prompts to generate landing pages for mobile or web applications.
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_human_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Originality
  - name: logos
    display_name: Logos
    description: Prompts to generate logos for brands and companies
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_human_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Originality
  - name: magazine_cover
    display_name: Magazine Cover Photos
    description: Prompts to generate magazine cover photos
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_human_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_human_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Originality
  - name: common_syntactic_processes
    display_name: Common Syntactic Processes
    description: Prompts from 8 different grammatical phenomena ([paper](https://arxiv.org/abs/2210.12889)).
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Reasoning
  - name: draw_bench_reasoning
    display_name: DrawBench (reasoning categories)
    description: A comprehensive and challenging set of prompts that support the evaluation and comparison of text-to-image models.
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Reasoning
  - name: parti_prompts_reasoning
    display_name: PartiPrompts (reasoning categories)
    description: PartiPrompts (P2) is a set of 1600 diverse English prompts that allow us to more comprehensively evaluate and test the limits of text-to-image synthesis models.
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Reasoning
  - name: relational_understanding
    display_name: Relational Understanding
    description: Based on existing cognitive, linguistic, and developmental literature, the authors created a set of 15 relations (8 physical, 7 agentic) and a set of 12 entities (6 objects, 6 agents)
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Reasoning
  - name: detection
    display_name: Detection (PaintSkills)
    description: A compositional diagnostic dataset an evaluation toolkit that measures visual reasoning skills ([paper](https://arxiv.org/abs/2202.04053)).
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_reasoning_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Reasoning
  - name: winoground
    display_name: Winoground
    description: Winoground is a novel task and dataset for evaluating the ability of vision and language models to conduct visio-linguistic compositional reasoning ([paper](https://arxiv.org/abs/2204.03162)).
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_quality_automated_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Reasoning
  - name: parti_prompts_knowledge
    display_name: PartiPrompts (knowledge categories)
    description: PartiPrompts (P2) is a set of 1600 diverse English prompts that allow us to more comprehensively evaluate and test the limits of text-to-image synthesis models.
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Knowledge
  - name: draw_bench_knowledge
    display_name: DrawBench (knowledge categories)
    description: A comprehensive and challenging set of prompts that support the evaluation and comparison of text-to-image models.
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Knowledge
  - name: time_most_significant_historical_figures
    display_name: TIME's most significant historical figures
    description: People from TIME's "The 100 Most Significant Figures in History" list
    metric_groups:
      - vhelm_alignment_human_metrics
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Knowledge
  - name: demographic_stereotypes
    display_name: Demographic Stereotypes
    description: Simple user prompts ("A photo of the face of...") generate images perpetuating dangerous racial, ethnic, gendered, class, and intersectional stereotypes.
    metric_groups:
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_bias_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Unbiasedness
  - name: mental_disorders
    display_name: Mental Disorders
    description: Prompt text-to-image models with mental disorders listed by the World Health Organization
    metric_groups:
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_bias_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_fairness_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Unbiasedness
  - name: i2p
    display_name: Inappropriate Image Prompts (I2P)
    description: Contains real user prompts for generative text-to-image prompts that are likely to produce inappropriate images ([paper](https://arxiv.org/abs/2211.05105)).
    metric_groups:
      - vhelm_alignment_clip_metrics
      - vhelm_aesthetics_automated_metrics
      - vhelm_originality_watermark_metrics
      - vhelm_toxicity_metrics
      - vhelm_toxicity_black_metrics
      - vhelm_toxicity_nudity_metrics
      - vhelm_robustness_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Toxicity mitigation
